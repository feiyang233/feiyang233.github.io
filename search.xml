<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[那些年在新加坡吃过的店]]></title>
    <url>%2Fpost%2FSG-food%2F</url>
    <content type="text"><![CDATA[民以食为天作为一个在新加坡搬砖的四川吃货，唯有美食不可辜负。坡县虽小，但各式各样的菜系都可以吃到。由于在四川长大，比较喜欢川菜火锅串串香锅烤鱼等。偶尔也跟着朋友们尝试一下其他的菜系。 川菜NTU Canteen 11 川菜 地址：20 Nanyang Ave, Singapore 639809 点评：目前吃过的新加坡性价比最高的川菜，味道好，价格最便宜，随便点还没有踩雷过。唯一的缺点就是地理位置太偏远了。 上图: 牛车水食阁 川味园 地址：32 New Market Rd, Singapore 050032 点评：德阳大叔开的店，味道非常的四川，价格实惠，分量也很足。只是在食阁里比较吵杂，还有点热。沸腾鱼我觉得很一般，不是很入味。据说旁边那家日日红麻辣香锅很不错，还没去吃过。 上图: 厦门街 成都 地址：74 Amoy St, Singapore 069893 点评：新加坡的四川同学安利的，水煮鱼，牛蛙强推，干锅肥肠也不错(但我觉得老成都的干锅肥肠更好吃)。辣子鸡不要点，辣鸡。 上图: 牛车水 老成都 地址：80 Pagoda St, Singapore 059239 点评：曾经我以为这家是热门景点宰客的店，虽然价格是贵，但人家的味道对得起老成都这个名字。目前吃过干锅肥肠，豆花牛肉，炒时蔬，nice！ 无图：吃的时候没有拍照，O(∩_∩)O哈哈~ 金文泰食阁 四川厨子 地址：450 Clementi Ave 3, #01-271, Singapore 120450 点评：窗口那个姐姐是四川邛崃的，目前只吃过她家的烧鸡公一次，味道不错。川菜水煮鱼不错，孜然排骨太干了，不行。 上图: NUS PGP食堂 川菜 地址：23 Prince George’s Park, Singapore 118422 点评：四川厨师，在蜀香吃过一次干煸肥肠，有点干煸过头。2019-03-27 吃了一次水煮肉片，味道很棒。有空调那家卖面条的姐姐是四川大邑的(好像又换人了)，没有空调卖面条的那个锅锅是四川泸州的。没有空调最里面那家我也吃过川菜，味道还行吧。 上图: NUS Utown 川菜 地址：2 College Ave West, Level 2 Stephen Riady Centre, Singapore 138607 点评：东北厨师，配菜是德阳小姐姐。分量是真的足，但味道就很一般了，学校食堂比较便宜。小炒肉、夫妻肺片还不错吧，水煮鱼 鱼香茄子 宫保鸡丁打扰了。 上图: 蜀香添一点 地址：721 Clementi West Street 2, Singapore 120721 点评：以前读书的时候住在附近，经常和学长去这家吃饭。价格还行，有的菜味道还可以。口水鸡，夫妻肺片凉菜不错。小炒肉，鱼香肉丝也行。大盘鸡 辣子鸡 水煮肉片 再见！ 上图: 天府川菜 地址：3151 Commonwealth Ave W, #01-17/18, Singapore 129581 点评：去吃过一次，我觉得酸菜鱼很一般，那个炒莲白更是不行啊。感觉辣椒没有几个，味道非常辣，像是放了辣椒素的感觉。 上图: 四川豆花饭庄 地址：7500 Beach Rd, Singapore 199591 点评：某次志愿者活动结束后去吃过一次。饭店的环境不错，豆花可以但分量超级小，其余的菜就很一般啦，我一点印象都没得咯。 上图: 老四川 看网红博主的测评视频 思味冒菜 地址: 33 Mosque St, Singapore 059511 点评： 我真的佛了，就成都gai上随便吃个冒菜，都比他家的好吃。真的太淡了，除了油，不辣不香，吃了想打人。泡椒牛蛙反而还不错的。 上图： A ONE 地址：23 Serangoon Central, #B1-73/74, Singapore 556083 serangoon 地铁站旁 点评：其实是一家本地的店，居然也有麻辣系列。但分量较小，味道还行。水煮鱼的鱼肉不行，肉质差。水煮肉片的淀粉少了，不够嫩。人均 30 新吧 上图： 火锅小龙坎 地址：牛车水或者武吉士 点评： 每年愚人节的那个周末，全球的小龙坎全场半价，抓住机会。平时人均 60 新，味道不错。 上图： 大龙燚 地址：乌节路，somerset 楼上 181 Orchard Rd, #08-08, Singapore 238896 点评：也是又贵又好吃的那种火锅。贫穷限制了我吃火锅。 上图： 同心如意火锅 地址：克拉码头 6 Lor Telok, Singapore 049019 点评：强烈安利了，真的好吃又不贵，环境还优雅，免费的西瓜深受吃瓜群众的喜爱。人均 30-40 新币 上图： 重庆小木凳火锅 地址： 牛车水 279 New Bridge Rd, Singapore 088752 点评： 小组聚餐吃过一次，人均 30-35 新，味道还是非常的不错，环境也还是可以的。 上图： 居然无图，忘了拍照。。。。食间火锅 地址：jurong east 和 Suntec City 点评：老板小武哥哥是 MIT 毕业的重庆大佬，食材新鲜，味道不错。Suntec City 还有自助火锅，人均在 30 新左右。 上图： 优品火锅 地址： 全岛有几家，我吃的是 west coast plaza 那一家 154 West Coast Rd, #01-02, Singapore 127371 点评： 出乎意料的火锅，以为是一家不知名的小店，结果味道很不错。人均 40+ 新 上图： 食立方火锅 地址：全岛连锁,我吃的是 west coast plaza 那一家 154 West Coast Road 127371, 02-24 West Coast Rd, Singapore 127447 点评：吃火锅送公仔娃娃是这家店最大的特色。味道不辣，适合口味淡的朋友们。人均 30 新左右。 上图： 潮汕牛肉火锅 地址: 195 E Coast Rd, Singapore 428900 点评：地理位置有点偏，但味道还不错，一共吃了三次。他家的牛肉粉真是一绝，但我们在吃第三次的时候，有的牛肉居然是冷冻拿出来的，反应给老板。老板态度良好，道歉还打了8折。希望他们越办越好吧。 上图： 满族火锅 地址: 350 Jurong East Ave 1, #01-1231 Singapore Singapore Region, Singapore 600350 点评：裕华园地铁出来，食阁附近的一家小店。那一排的店家都是这个风格，可能是地理位置偏远，价格非常便宜，味道还行。 上图： 串串嘿串串 地址： 291 South Bridge Rd, Singapore 058836 点评： 可以做游戏打折，比如立定跳远。还有自助串串，我觉得一般般。感觉好像味道下降了？ 上图： 重庆李记串串 地址： 295 South Bridge Rd, Singapore 058838 South Bridge Rd, Singapore 058838，巧了就在嘿串串旁边 点评： 一年前吃过一次，味道还不错，感觉性价比 比嘿串串高，但店面环境没有嘿串串好。 上图： 香锅Timbre大海麻辣香锅 地址：73A Ayer Rajah Crescent, JTC Launchpad, Singapore 139957 one north 地铁站出来 Timbre+ 食阁里 点评：非常温和的一家香锅，记得喊老板多放油。毛肚不错哦，还可以送外卖的。人均 8-15 新 上图：OneNorth口福麻辣香锅 地址：1 Fusionopolis Way, Singapore 138577 One North 口福 点评：他们家放的芝麻可是真的比较多，真香！ 上图： Galaxis二楼麻辣香锅 地址： 1 Fusionopolis Pl, Singapore 138522 Galaxis 二楼食阁 点评： 有一个绵阳的哥哥在这里，是我看到过的第一家荤素菜不分开计算重量的麻辣香锅。所以也就是最便宜的麻辣香锅。 上图： 宽宽干锅 地址：38 Mosque St, Singapore 059516 点评：是伟翔锅锅请我这个小弟吃的，味道不错，和国内的干锅比较相似。鸭掌还不够糯，比起成都的销魂掌还是有点差距的。 上图： 美蛙烤鱼探鱼 地址：313 Orchard Rd, Singapore 238895 点评：新加坡吃过最好吃的烤鱼，肉质不是油炸的那种烤鱼。推荐鲜青椒烤鱼，重庆豆花烤鱼。人均 30-40 新 上图: 蛙功夫 地址: 牛车水店 470 North Bridge Rd, Singapore 188735 点评：微信提前预定打九折。新加坡第一蛙了，怪椒味和姜辣味真的好辣啊，四川人都遭不住了。 人均 30-40 新 上图： 齐来丰酸菜鱼 地址: 133 New Bridge Road B1-14/15 Chinatown Point S059413 点评： 新加坡眼推荐 味道还不错，价格还可以接受，可以试一试。 上图： 螃蟹Long Seafood 地址： Ang Mo Kio Avenue 3, #01-1222,Block 232, Singapore 560232 龙海鲜螃蟹王宏茂桥店 点评： 在一个食阁的一楼，店面很大。米粉螃蟹不错，人均 70 新币 上图： Mellben Signature 地址：7 Tanjong Pagar Plaza, #01-105, Singapore 081007 点评： 人均 60 新币，感觉螃蟹小一点点，没有宏茂桥那家好吃，米粉螃蟹的话。 上图： 烤肉烤串Supulae 李加绒同学倾情推荐，还没有来得及去吃。Super Star K 地址75 Tg Pagar Rd, Singapore 088496 点评：吃过3次了，那一条街大部分店面都是晚上营业，他家是少有的中午也开门。味道不错，分量也很足。服务员还会帮忙烤肉，态度也很好的。人均 40 新左右，推荐。 上图： GO! K - BBQ 地址/@1.2805141,103.8444605,17z/data=!3m1!4b1!4m5!3m4!1s0x31da190d6ec97b63:0x8df5f639962a0c51!8m2!3d1.2805087!4d103.8466492)76 Amoy St, Singapore 069895 就在川菜《成都》店旁边，都在厦门街 点评：晚上才开，人很多，最好提前预定。他家的肉是腌制过后的肉，味道更加的美味。但感觉服务员少了，有点忙不过来。肉的分量稍微小点，价格也就偏贵。 上图： 烧肉王子 地址: 321 Clementi Ave 3, #01-01, Singapore 129905 点评： 日式的自助烤肉，分为三个等级：只有鸡肉，有猪肉牛肉，顶级和牛。我们当时吃的是中间那个档次，人均 32 新币。 上图： 大胡子烧烤 地址: 70 Lor 25A Geylang, Singapore 388255 点评： 就在 Aljunied 地铁站出来，烤串是非常不错。干锅肥肠还需要煎的更焦一点。 店里有点炒闹，吃饭时感觉回到了国内小城市的街边小店。 上图： 香港小厨 地址: 24 Clementi Rd, Singapore 129753 点评：就在 NUS 后街，烤串还是不错的，烤羊排不行，少的太真实了。烤韭菜，一定要让老板少放点盐啊！ 上图: 王大爷烧烤 地址: 16 Mosque St, Singapore 059496 点评：在牛车水摩士街，有点小贵。店面环境还不错，味道一般般，那个柴火鸡一定不要点，比起成都的差太多了，吃了想打人。 上图： HANSSIK 地址: 3155 Commonwealth Ave W, #05-17/18, Singapore 129588 点评： 金文泰商场 5 楼，一家自助烤肉，味道还行吧，人均 33 新。吃到最后有点闷了。。。。 上图： 鸡饭了凡香港油鸡饭 地址：78 Smith St, Singapore 058972 点评： 米其林一星的鸡饭，我觉得可以。 上图： 天天海南鸡饭待吃荣亮阁 地址: #01-192, 725 Clementi West Street 2, Block 725, Singapore 120725 点评：家附近的一家鸡饭店，本地人经常去吃，物美价廉。 上图： 其他美食莆田 地址: 1 HarbourFront Walk #02-131/132 点评： 一家非常不错的福建菜。空调有点冷，九转粉肠非常的好吃，虾苗拌紫菜也好吃，蛏子也很大只的。百秒黄花鱼也是很嫩。扁肉汤的馄饨好吃，汤一般般。蔬菜豆腐汤不错，很好喝推荐。脆皮蒜香鸡不行，不推荐。 上图：]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>美食</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运维中踩过的坑]]></title>
    <url>%2Fpost%2Fops-bug%2F</url>
    <content type="text"><![CDATA[仅以本文记录那些年弟弟背过的锅！ iptables 大部分时候，iptables 只存了 filter 表。 对于 nat 表，我们一旦 restart iptables， nat 表的规则就会被刷新。建议用 reload -A INPUT -m state –state RELATED,ESTABLISHED -j ACCEPT 这一条 iptables 的规则也非常重要。Packets in a RELATED or ESTABLISHED state are those ones which belong to an already opened connection; you’ll generally want to accept them, otherwise connections will get established correctly but nothing will be able to flow after the initial handshake. 如果没有这一条，会遇到 DNS 解析失败， curl 失败。 凡是 iptables 没有允许的 IP, 都不能正常的工作。 例如 DNS 查询发包后，三次握手建立。回包收到了，却会被 iptables 阻挡，上层应用无法拿到解析的结果，导致 hang 住。 tcpdump 抓包分析时， 进入的包都可以抓到，不会受到 iptables, 发出的包会受到 iptables 影响，可能被 iptables 阻挡导致抓包失败。 如果是命令行添加的规则，例如 iptables -t nat -A OUTPUT -s 172.17.0.3 -p tcp –dport 10050 -j ACCEPT 在使用 reload 后，其规则一样会被刷掉。但 docker 的规则不会被 reload 刷掉，会被 restart 刷掉。这一点又疑问，期待大神给弟弟解惑。 python tab 键与空格不能混用 函数不要嵌套，例如 result=A(B(C())) 这样不利于 debug，检查每个函数的返回值 在 multiprocessing 多进程中 apply_async() 报错不容易定位，最好使用 try catch 把报错写成 log jenkins 在部署的时候，ansible 一直在 gathering facts 卡住了，直到 timeout。 网友解答 我遇到的是 control_path 文件太多了，导致了 jenkins deploy node 卡住，任务无法进行。 需要删除该部署节点下面的 control_path_dir 的文件，清空。 docker docker container IP default is 172.17.0.0/16 检查 iptables 是否阻挡 docker -v 挂载出来的时候，要注意文件夹权限问题。 docker logs 日志文件很大的时候，记得删除。Docker容器日志查看与清理 NetworkManager 报错 bus-manager: could not create org.freedesktop.DBus proxy 直接 stop NetworkManager 就行了。 文件权限问题 /tmp permission 又搞我 对于目录文件来说，可读表示能够读取目录内的文件列表；可写表示能够在目录内新增、删除、重命名文件；可执行表示能够进入该目录。 DNS /etc/resolv.conf 有两个默认的值至关重要，一个是超时的 timeout，一个是重试的 attempts，默认情况下，前者是 5s 后者是 2 次。对于日常的应用来说，包括 web server、mail client、db 以及各种 app server 等等，任何使用 glibc resolver 都需要经过 resolv.conf 文件。对于 libresolv 来说，只认 resolv.conf 的前三个 nameserver，所以写的再多也没什么意义。正常情况下，resolver 会从上至下进行解析，每个 nameserver 等待 timeout 的时间，如果一直到第三个都没结果，resolver 会重复上面的步骤 (attempts – 1) 次。 Ansible user 模块，密码必须要加密。需要用到 Ansible ad-hoc command]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>docker</tag>
        <tag>elk</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix 从入门到放弃]]></title>
    <url>%2Fpost%2Fzabbix%2F</url>
    <content type="text"><![CDATA[docker 安装 zabbix, 添加主机，设置报警，性能调优。 docker 搭建12345678910# install docker-cesudo yum install -y yum-utils device-mapper-persistent-data lvm2sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.reposudo yum install -y docker-cesudo systemctl start docker# 做数据映射后的方案 mkdir -p /data/docker/mysql/zabbix/datamkdir -p /data/docker/zabbix/alertscriptsmkdir -p /data/docker/zabbix/externalscripts 然后是安装 zabbix 前端，后端，数据库。123456789# 数据库。docker run --name mysql-server -t \-e MYSQL_DATABASE="zabbix" \-e MYSQL_USER="zabbix" \-e MYSQL_PASSWORD="feiyang@2019+" \-e MYSQL_ROOT_PASSWORD="feiyang@2019+" \-v /data/zabbix_data:/var/lib/mysql \-d mysql:5.7 \--character-set-server=utf8 --collation-server=utf8_bin 12345678910111213141516171819# 后端 参数已经调优docker run --name zabbix-server-mysql \-e DB_SERVER_HOST="mysql-server" \-e MYSQL_DATABASE="zabbix" \-e MYSQL_USER="zabbix" \-e MYSQL_PASSWORD="feiyang@2019+" \-e MYSQL_ROOT_PASSWORD="feiyang@2019+" \-e ZBX_TIMEOUT=30 \-e ZBX_CACHESIZE=8G \-e ZBX_TRENDCACHESIZE=2G \-e ZBX_STARTPOLLERS=500 \-e ZBX_STARTPOLLERSUNREACHABLE=100 \-e ZBX_HOUSEKEEPINGFREQUENCY=0 \-v /data/zabbix/alertscripts:/usr/lib/zabbix/alertscripts \-v /data/zabbix/externalscripts:/usr/lib/zabbix/externalscripts \-v /data/zabbix/conf:/etc/zabbix \--link mysql-server:mysql \-p 10051:10051 \-d zabbix/zabbix-server-mysql:centos-4.2-latest 123456789101112# 前端docker run --name zabbix-web-nginx-mysql \-e DB_SERVER_HOST="mysql-server" \-e MYSQL_DATABASE="zabbix" \-e MYSQL_USER="zabbix" \-e MYSQL_PASSWORD="feiyang@2019+" \-e MYSQL_ROOT_PASSWORD="feiyang@2019+" \-e PHP_TZ="Asia/Singapore" \--link mysql-server:mysql \--link zabbix-server-mysql:zabbix-server \-p 8080:80 \-d zabbix/zabbix-web-nginx-mysql:centos-4.2-latest 安装完成后，在浏览器打开 http://localhost:8080 默认的账户是 Admin 密码是 zabbix ansible 批量添加主机123456789101112131415161718192021222324--- - name: add zabbix hosts local_action: module: zabbix_host server_url: "&#123;&#123; var_server_url &#125;&#125;" login_user: "&#123;&#123; var_login_user &#125;&#125;" login_password: "&#123;&#123; var_login_password &#125;&#125;" host_name: "&#123;&#123; inventory_hostname &#125;&#125;" visible_name: "&#123;&#123; inventory_hostname &#125;&#125;-&#123;&#123;function&#125;&#125;" host_groups: - "&#123;&#123; var_host_group &#125;&#125;" link_templates: - Template Sea Ops OS Linux - Template Sea Ops Disk IO Linux #status: disabled status: enabled state: present interfaces: - type: 1 main: 1 useip: 1 ip: "&#123;&#123; var_lanip | default(inventory_hostname) &#125;&#125;" dns: "" port: 10050 Action设置触发警告的 Action 时，当 Step 设置为从 1 到 0 时，会一直发送告警信息，直到事件状态变成 OK，当 Step 设置为从 1 到 1 时，则只会发送一次告警，后面不会继续发送告警信息。 Zabbix 监控监控网页状态zabbix 自带的 Web monitoring 就可以进行简单的网页监控。目前官方的 zabbix 版本是 4.2 此时日期 2019-07-09首先是找到一台机器 Go to Configuration → Hosts, pick a host and click on Web in the row of that host. Then click on Create web scenario. 详情请看官方文档，然后是添加报警，网页监控的官方文档也是介绍的非常详细。具体的监控图表信息，可以在 zabbix 主页的 Monitoring -&gt; Web 可以看到网页监控的详细信息。 监控 DNS官方文档 4.2 版本zabbix默认支持检查解析成功与否和具体的解析结果。对应内置的KEY123456789net.dns[&lt;ip&gt;,zone,&lt;type&gt;,&lt;timeout&gt;,&lt;count&gt;]net.dns.record[&lt;ip&gt;,zone,&lt;type&gt;,&lt;timeout&gt;,&lt;count&gt;]ip 指DNS服务器地址。zone 指要解析的域名type 指解析的记录类型timeout 指超时时间 默认1 秒count 指解析失败重试的次数 默认 2次trigger &#123;host:net.dns[dns_server,domain,A,1,2].count(#3)&#125;=0 数据库表优化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176DELIMITER $$CREATE PROCEDURE `partition_create`(SCHEMANAME varchar(64), TABLENAME varchar(64), PARTITIONNAME varchar(64), CLOCK int)BEGIN /* SCHEMANAME = The DB schema in which to make changes TABLENAME = The table with partitions to potentially delete PARTITIONNAME = The name of the partition to create */ /* Verify that the partition does not already exist */ DECLARE RETROWS INT; SELECT COUNT(1) INTO RETROWS FROM information_schema.partitions WHERE table_schema = SCHEMANAME AND table_name = TABLENAME AND partition_description &gt;= CLOCK; IF RETROWS = 0 THEN /* 1. Print a message indicating that a partition was created. 2. Create the SQL to create the partition. 3. Execute the SQL from #2. */ SELECT CONCAT( "partition_create(", SCHEMANAME, ",", TABLENAME, ",", PARTITIONNAME, ",", CLOCK, ")" ) AS msg; SET @sql = CONCAT( 'ALTER TABLE ', SCHEMANAME, '.', TABLENAME, ' ADD PARTITION (PARTITION ', PARTITIONNAME, ' VALUES LESS THAN (', CLOCK, '));' ); PREPARE STMT FROM @sql; EXECUTE STMT; DEALLOCATE PREPARE STMT; END IF;END$$DELIMITER ;DELIMITER $$CREATE PROCEDURE `partition_drop`(SCHEMANAME VARCHAR(64), TABLENAME VARCHAR(64), DELETE_BELOW_PARTITION_DATE BIGINT)BEGIN /* SCHEMANAME = The DB schema in which to make changes TABLENAME = The table with partitions to potentially delete DELETE_BELOW_PARTITION_DATE = Delete any partitions with names that are dates older than this one (yyyy-mm-dd) */ DECLARE done INT DEFAULT FALSE; DECLARE drop_part_name VARCHAR(16); /* Get a list of all the partitions that are older than the date in DELETE_BELOW_PARTITION_DATE. All partitions are prefixed with a "p", so use SUBSTRING TO get rid of that character. */ DECLARE myCursor CURSOR FOR SELECT partition_name FROM information_schema.partitions WHERE table_schema = SCHEMANAME AND table_name = TABLENAME AND CAST(SUBSTRING(partition_name FROM 2) AS UNSIGNED) &lt; DELETE_BELOW_PARTITION_DATE; DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE; /* Create the basics for when we need to drop the partition. Also, create @drop_partitions to hold a comma-delimited list of all partitions that should be deleted. */ SET @alter_header = CONCAT("ALTER TABLE ", SCHEMANAME, ".", TABLENAME, " DROP PARTITION "); SET @drop_partitions = ""; /* Start looping through all the partitions that are too old. */ OPEN myCursor; read_loop: LOOP FETCH myCursor INTO drop_part_name; IF done THEN LEAVE read_loop; END IF; SET @drop_partitions = IF(@drop_partitions = "", drop_part_name, CONCAT(@drop_partitions, ",", drop_part_name)); END LOOP; IF @drop_partitions != "" THEN /* 1. Build the SQL to drop all the necessary partitions. 2. Run the SQL to drop the partitions. 3. Print out the table partitions that were deleted. */ SET @full_sql = CONCAT(@alter_header, @drop_partitions, ";"); PREPARE STMT FROM @full_sql; EXECUTE STMT; DEALLOCATE PREPARE STMT; SELECT CONCAT(SCHEMANAME, ".", TABLENAME) AS `table`, @drop_partitions AS `partitions_deleted`; ELSE /* No partitions are being deleted, so print out "N/A" (Not applicable) to indicate that no changes were made. */ SELECT CONCAT(SCHEMANAME, ".", TABLENAME) AS `table`, "N/A" AS `partitions_deleted`; END IF;END$$DELIMITER ;DELIMITER $$CREATE PROCEDURE `partition_maintenance`(SCHEMA_NAME VARCHAR(32), TABLE_NAME VARCHAR(32), KEEP_DATA_DAYS INT, HOURLY_INTERVAL INT, CREATE_NEXT_INTERVALS INT)BEGIN DECLARE OLDER_THAN_PARTITION_DATE VARCHAR(16); DECLARE PARTITION_NAME VARCHAR(16); DECLARE OLD_PARTITION_NAME VARCHAR(16); DECLARE LESS_THAN_TIMESTAMP INT; DECLARE CUR_TIME INT; CALL partition_verify(SCHEMA_NAME, TABLE_NAME, HOURLY_INTERVAL); SET CUR_TIME = UNIX_TIMESTAMP(DATE_FORMAT(NOW(), '%Y-%m-%d 00:00:00')); SET @__interval = 1; create_loop: LOOP IF @__interval &gt; CREATE_NEXT_INTERVALS THEN LEAVE create_loop; END IF; SET LESS_THAN_TIMESTAMP = CUR_TIME + (HOURLY_INTERVAL * @__interval * 3600); SET PARTITION_NAME = FROM_UNIXTIME(CUR_TIME + HOURLY_INTERVAL * (@__interval - 1) * 3600, 'p%Y%m%d%H00'); IF(PARTITION_NAME != OLD_PARTITION_NAME) THEN CALL partition_create(SCHEMA_NAME, TABLE_NAME, PARTITION_NAME, LESS_THAN_TIMESTAMP); END IF; SET @__interval=@__interval+1; SET OLD_PARTITION_NAME = PARTITION_NAME; END LOOP; SET OLDER_THAN_PARTITION_DATE=DATE_FORMAT(DATE_SUB(NOW(), INTERVAL KEEP_DATA_DAYS DAY), '%Y%m%d0000'); CALL partition_drop(SCHEMA_NAME, TABLE_NAME, OLDER_THAN_PARTITION_DATE);END$$DELIMITER ;DELIMITER $$CREATE PROCEDURE `partition_verify`(SCHEMANAME VARCHAR(64), TABLENAME VARCHAR(64), HOURLYINTERVAL INT(11))BEGIN DECLARE PARTITION_NAME VARCHAR(16); DECLARE RETROWS INT(11); DECLARE FUTURE_TIMESTAMP TIMESTAMP; /* * Check if any partitions exist for the given SCHEMANAME.TABLENAME. */ SELECT COUNT(1) INTO RETROWS FROM information_schema.partitions WHERE table_schema = SCHEMANAME AND table_name = TABLENAME AND partition_name IS NULL; /* * If partitions do not exist, go ahead and partition the table */ IF RETROWS = 1 THEN /* * Take the current date at 00:00:00 and add HOURLYINTERVAL to it. This is the timestamp below which we will store values. * We begin partitioning based on the beginning of a day. This is because we don't want to generate a random partition * that won't necessarily fall in line with the desired partition naming (ie: if the hour interval is 24 hours, we could * end up creating a partition now named "p201403270600" when all other partitions will be like "p201403280000"). */ SET FUTURE_TIMESTAMP = TIMESTAMPADD(HOUR, HOURLYINTERVAL, CONCAT(CURDATE(), " ", '00:00:00')); SET PARTITION_NAME = DATE_FORMAT(CURDATE(), 'p%Y%m%d%H00'); -- Create the partitioning query SET @__PARTITION_SQL = CONCAT("ALTER TABLE ", SCHEMANAME, ".", TABLENAME, " PARTITION BY RANGE(`clock`)"); SET @__PARTITION_SQL = CONCAT(@__PARTITION_SQL, "(PARTITION ", PARTITION_NAME, " VALUES LESS THAN (", UNIX_TIMESTAMP(FUTURE_TIMESTAMP), "));"); -- Run the partitioning query PREPARE STMT FROM @__PARTITION_SQL; EXECUTE STMT; DEALLOCATE PREPARE STMT; END IF;END$$DELIMITER ;DELIMITER $$CREATE PROCEDURE`partition_maintenance_all`(SCHEMA_NAME VARCHAR(32))BEGIN CALL partition_maintenance(SCHEMA_NAME, 'history', 30, 24, 14); CALL partition_maintenance(SCHEMA_NAME, 'history_log', 30, 24, 14); CALL partition_maintenance(SCHEMA_NAME, 'history_str', 30, 24, 14); CALL partition_maintenance(SCHEMA_NAME, 'history_text', 30, 24, 14); CALL partition_maintenance(SCHEMA_NAME, 'history_uint', 30, 24, 14); CALL partition_maintenance(SCHEMA_NAME, 'trends', 120, 24, 14); CALL partition_maintenance(SCHEMA_NAME, 'trends_uint', 120, 24, 14);END$$DELIMITER ; Trends 120,(‘history’, 30, 24, 14), 最多保存 30 天的数据，每隔 24 小时生成一个分区，每次生成 14 个分区 首先进入容器内部，将上面这个 partition.sql 导入数据库 mysql12345678mysql -uzabbix -pfeiyang@2019+ zabbix &lt; partition.sql# 在 mysql 容器内部 vim /opt/mysql.sh#!bin/bashmysql -uzabbix -pfeiyang@2019+ zabbix -e"CALL partition_maintenance_all('zabbix')" chmod 755 /opt/mysql.sh 退出容器，在宿主机上，建立定时任务 12345# vim /etc/crontab23 03 * * * root /bin/docker exec [mysql 容器 ID] bash -c "cd /opt &amp;&amp; bash mysql.sh" systemctl restart crond Zabbix api123456789101112131415161718192021222324252627282930# auth_zabbiximport requestsimport jsonurl = 'http://IP:port/api_jsonrpc.php' #docker 方式# 非 docker 方式为 "http://IP:port/zabbix/api_jsonrpc.php"post_data = &#123; "jsonrpc": "2.0", "method": "user.login", "params": &#123; "user": "xxx", "password": "xxx" &#125;, "id": 1, &#125;post_header = &#123;'Content-Type': 'application/json'&#125;ret = requests.post(url, data=json.dumps(post_data), headers=post_header)#print(ret)zabbix_ret = json.loads(ret.text)if not zabbix_ret.has_key('result'): print 'login error'else: print zabbix_ret.get('result') 123456789101112131415161718192021222324252627282930313233343536373839404142# get hostidimport requestsimport jsonurl = 'http://IP:port/api_jsonrpc.php'server_list=["1.1.1.1","233.233.233.233"]post_data = &#123; "jsonrpc": "2.0", "method": "host.get", "params": &#123; "filter": &#123; "host": server_list &#125;, "sortfield": "host", &#125;, "id": 1, "auth": "由上文中的 auth_zabbix.py 得出"&#125;post_header = &#123;'Content-Type': 'application/json'&#125;ret = requests.post(url, data=json.dumps(post_data), headers=post_header)zabbix_ret = json.loads(ret.text)print zabbix_retif not zabbix_ret.has_key('result'): print 'login error'else: print zabbix_ret.get('result') hostid_list=[]for i in zabbix_ret.get('result'): hostid_list.append(str(i['hostid']))print hostid_list 123456789101112131415161718192021222324252627282930313233343536373839404142# get hist_dataimport requestsimport jsonimport timeimport datetimetoday = datetime.date.today()today_unix = int(time.mktime(today.timetuple()))tomorrow = today+datetime.timedelta(days=1)tomorrow_unix = int(time.mktime(tomorrow.timetuple()))print today_unixprint tomorrow_unixurl = 'http://IP:port/api_jsonrpc.php'post_data = &#123; "jsonrpc": "2.0", "method": "history.get", "params": &#123; "output": "extend", "history": 3, # 0,1,2,3,4 "itemids": "31023", "sortfield": "clock", "sortorder": "DESC", "time_from": "today_unix", "time_till": "tomorrow_unix" &#125;, "auth": "由上文中的 auth_zabbix.py 得出", "id": 1&#125;post_header = &#123;'Content-Type': 'application/json'&#125;ret = requests.post(url, data=json.dumps(post_data), headers=post_header)zabbix_ret = json.loads(ret.text)print zabbix_ret.get('result') zabbix_get从 server 端检测到 client 端的网络是否通畅，可能是 iptables 或者 server host 白名单造成的问题。1zabbix_get -s 10.10.1.1 -k system.uname]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络相关]]></title>
    <url>%2Fpost%2Fnetwork%2F</url>
    <content type="text"><![CDATA[记录网络相关知识与 Linux 网络相关的命令。 Linux 命令 route 某些 IP 段故障 mtr 连通性测试 Linux 常用网络指令 iptables 奥哥篇 iptables-NAT iperf 测试网速的工具 删除网卡 ip link delete [网卡名称] 检查未被正确关闭的文件 lsof 磁盘监控命令iostat iptables12345678910iptables -t nat -nL # 查看 nat 表iptables -t 表名 -N 自定义链名 # 创建一个链iptables -t 表名 -L default filteriptables -t 表名 -L 链名iptables -t 表名 -nL --lineiptables -t 表名 -D 链名 要删除的序号iptables -t 表名 -P 链名 动作 修改默认规则 DROP-A INPUT -m iprange --src-range x.x.x.x-x.x.x.x -p tcp --dport 11211 -j ACCEPT 类型匹配 -p tcp udp udplite icmp icmpv6 esp ah sctp mh转发功能 cat /proc/sys/net/ipv4/ip_forward 小知识Public IP Class A: 0.x.x.x ~ 127.x.x.x Class B: 128.x.x.x ~ 191.x.x.x Class C: 192.x.x.x ~ 223.x.x.x Class D: 224.x.x.x ~ 239.x.x.x #multicast Class E: 240.x.x.x ~ 255.x.x.x #保留 Private IP Class A: 10.0.0.0 ~ 10.255.255.255 Class B: 172.16.0.0 ~ 172.31.255.255 Class C: 192.168.0.0 ~ 192.168.255.255 169.254.x.x 临时 IP DHCP is full. 就用这个 IP Loopback IP Class A: 127.0.0.1/8 设置 NAT server开启转发功能12345vim /etc/sysctl.confnet.ipv4.ip_forward=1 # 添加此行，开启转发功能sysctl -p # 执行生效 还需要在 iptable 里设置转发规则12345678910111213vim /etc/sysconfig/iptables*nat:PREROUTING ACCEPT [0:0]:INPUT ACCEPT [0:0]:OUTPUT ACCEPT [0:0]:POSTROUTING ACCEPT [0:0]-A POSTROUTING -o em2 -j MASQUERADECOMMIT# em2 是公网网卡，当其他内网机器设置 NAT 机器的内网 IP 为网关时。 # 内网机器发包给 NAT 机器， NAT 机器根据路由规则，将会由 em2 公网网卡转发出去。# 转发时，会将包的源 IP 替换为自己公网的 IP tcpdump 抓包分析 进入 INPUT 的流量不会被 iptable 影响 出口 OUTPIT 流量会受到 iptable 影响 ICMP ping 默认发 4、5 个包 traceroute 显示的是不同 AS 之间的跳数。其实一个 AS 内部可能有很多路由器，TTL 与实际跳数是不符合的。 TCP 三次握手建立连接 四次分手，等待 2 MSL 只走一条路径 UDP 更轻更快 多条路径同时发送 DDos 攻击DDOS 攻击，它在短时间内发起大量请求，耗尽服务器的资源，无法响应正常的访问，造成网站实质下线。DDOS 里面的 DOS 是 denial of service（停止服务）的缩写，表示这种攻击的目的，就是使得服务中断。最前面的那个 D 是 distributed （分布式），表示攻击不是来自一个地方，而是来自四面八方，因此更难防。 比较常见的一种攻击是 cc 攻击。它就是简单粗暴地送来大量正常的请求，超出服务器的最大承受量，导致宕机。 SYN攻击属于DoS攻击的一种，它利用TCP协议缺陷，通过发送大量的半连接请求，耗费CPU和内存资源。SYN攻击除了能影响主机外，还可以危害路由器、防火墙等网络系统，事实上SYN攻击并不管目标是什么系统，只要这些系统打开TCP服务就可以实施。服务器接收到连接请求（syn= j），将此信息加入未连接队列，并发送请求包给客户（syn=k,ack=j+1），此时进入SYN_RECV状态。当服务器未收到客户端的确认包时，重发请求包，一直到超时，才将此条目从未连接队列删除。配合IP欺骗，SYN攻击能达到很好的效果，通常，客户端在短时间内伪造大量不存在的IP地址，向服务器不断地发送syn包，服务器回复确认包，并等待客户的确认，由于源地址是不存在的，服务器需要不断的重发直至超时，这些伪造的SYN包将长时间占用未连接队列，正常的SYN请求被丢弃，目标系统运行缓慢，严重者引起网络堵塞甚至系统瘫痪。 踩过的坑 docker container IP default is 172.17.0.0/16 检查 iptables 是否阻挡 -A INPUT -m state –state RELATED,ESTABLISHED -j ACCEPT 这一条 iptables 的规则也非常重要。Packets in a RELATED or ESTABLISHED state are those ones which belong to an already opened connection; you’ll generally want to accept them, otherwise connections will get established correctly but nothing will be able to flow after the initial handshake. 如果没有这一条，会遇到 DNS 解析失败， curl 失败。 凡是 iptables 没有允许的 IP, 都不能正常的工作。 例如 DNS 查询发包后，三次握手建立。回包收到了，却会被 iptables 阻挡，上层应用无法拿到解析的结果，导致 hang 住。 抓包分析时， 进入的包都可以抓到，不会受到 iptables, 发出的包会受到 iptables 影响，可能被 iptables 阻挡导致抓包失败。 在此衷心的感谢，皇族后裔，八旗子弟，爱新觉罗·高Li，提供的帮助！]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google API 学习]]></title>
    <url>%2Fpost%2Fgoogle-api%2F</url>
    <content type="text"><![CDATA[Python 修改 Google sheet官方文档记录一下自己调用 Google Api 的方法。 几个重要的概念 spreadsheetId 整个总表的 ID 是很长的一串字符 sheetId 单页的 ID 是纯数字 Get获取数据get 方法 1234567SAMPLE_SPREADSHEET_ID = spreadsheetIdSAMPLE_RANGE_NAME = 'feiyang!G1:G4'sheet = service.spreadsheets()result = sheet.values().get(spreadsheetId=SAMPLE_SPREADSHEET_ID, range=SAMPLE_RANGE_NAME).execute()values = result.get('values', []) Append Data123456789101112range_ = 'capacity-raw!A:E' # 表内的页名称 ! 范围value_input_option = 'USER_ENTERED' insert_data_option = 'INSERT_ROWS' value_range_body = &#123; "range": "capacity-raw!A:E","values": getdata.get_data(today,product),"majorDimension": "ROWS"&#125;request = service.spreadsheets().values().append(spreadsheetId=spreadsheet_id, range=range_, valueInputOption=value_input_option, insertDataOption=insert_data_option, body=value_range_body)response = request.execute() Update Data举个例子 1234567891011121314151617SAMPLE_SPREADSHEET_ID = 'xxxxxxxxx'SAMPLE_RANGE_NAME = 'daily_report!A9:D9'value_input_option = "RAW" # 还有其他的方式value_body = &#123; "majorDimension": "ROWS", "range": "daily_report!A9:D9", "values": [["test","123","a","b"]],&#125;sheet = service.spreadsheets()result = sheet.values().update(spreadsheetId=SAMPLE_SPREADSHEET_ID, range=SAMPLE_RANGE_NAME, valueInputOption=value_input_option,body=value_body)response = result.execute()pprint(response) Sheet Operation删除行，插入行，复制一行，最重要的是 post body 格式。 官方文档写得不够详细。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455delete_body =&#123; "requests": [ &#123; "deleteDimension": &#123; "range": &#123; "sheetId": 233333333, "dimension": "ROWS", "startIndex": 1, "endIndex": 2 &#125; &#125; &#125;, ],&#125;insert_body =&#123; "requests": [ &#123; "insertDimension": &#123; "range": &#123; "sheetId": 233333333, "dimension": "ROWS", "startIndex": 8, "endIndex": 9 &#125; &#125; &#125;, ],&#125;copy_body =&#123; "requests": [ &#123; "copyPaste": &#123; "source": &#123; "sheetId": 233333333, "startRowIndex": 6, "endRowIndex": 7, "startColumnIndex": 1, "endColumnIndex": 5 &#125;, "destination": &#123; "sheetId": 1172952310, "startRowIndex": 7, "endRowIndex": 8, "startColumnIndex": 1, "endColumnIndex": 5 &#125;, "pasteType": "PASTE_NORMAL", "pasteOrientation": "NORMAL" &#125; &#125; ]&#125; 然后是 Python post 部分123request = sheet.batchUpdate(spreadsheetId=SAMPLE_SPREADSHEET_ID, body=body_item)response = request.execute()pprint(response)]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>google</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prometheus 监控 memcached]]></title>
    <url>%2Fpost%2Fmemcached%2F</url>
    <content type="text"><![CDATA[本文记录如何用安装 memcached_exporter 来收集 memcached 信息并且暴露给 Prometheus 监听程序，Prometheus 将收集的信息传递给 grafana 进行信息可视化。 安装 Memcached Exporterprometheus 官方的 memcached_exporter 文档 bridge 桥接方式在 192.168.21.16 服务器上运行了三个 memcached 端口分别为 11211:11213 目前官方的这个版本还不支持多个地址，社区的解决方案点这里12345docker run -d -p 9211:9150 --name=memcached_11211 quay.io/prometheus/memcached-exporter:v0.5.0 --memcached.address=192.168.21.16:11211docker run -d -p 9212:9150 --name=memcached_11212 quay.io/prometheus/memcached-exporter:v0.5.0 --memcached.address=192.168.21.16:11212docker run -d -p 9213:9150 --name=memcached_11213 quay.io/prometheus/memcached-exporter:v0.5.0 --memcached.address=192.168.21.16:11213 在这里我们启动了三个 docker container 用的是 bridge 网络方式来分别监听 11211–11213 需要注意的是 memcached.address 默认监听的是 localhost:11211 如果是 bridge 方式的话，用默认的方法 localhost 只能监听到容器内部。 host 网络方式如果服务器只有一个 memcached 进程的话，那么我们可以用 host 网络的方式。 容器和服务器共享网络，优点是网络高性能，缺点就是需要注意端口冲突。1docker run --network=host --name=memcached_11211 quay.io/prometheus/memcached-exporter:v0.5.0 --memcached.address=localhost:11211 注意 iptable一旦使用了 docker 我们需要特别注意的就是 iptable -A INPUT -s 172.16.0.0/12 -j DROP #检查iptables filter 表 INPUT 链是否阻止了docker container IP，因为 docker 默认 IP 是 172.17.0.0/24， -A INPUT -s 172.17.0.0/24 -p tcp –dport 11211:11213 -j ACCEPT #若采用 bridge 桥接方式， 需要允许容器连接到 memcached -A INPUT -s Prometheus_IP -p tcp –dport 9211:9213 -j ACCEPT #给 Prometheus 开放监听的白名单 检查 memcached_exporter 结果1234567891011121314151617181920212223242526curl 172.17.0.2:9150/metrics #直接访问容器内部curl localhost:9211/metrics # 从docker暴露出来的端口访问# 结果中的字段在 grafana 设置图表时，相关的图表就要用对应的字段# 比如当前连接上 (memcached_current_connections&#123;instance=~"$node"&#125;) # TYPE memcached_connections_listener_disabled_total countermemcached_connections_listener_disabled_total 0# HELP memcached_connections_total Total number of connections opened since the server started running.# TYPE memcached_connections_total countermemcached_connections_total 255174# HELP memcached_connections_yielded_total Total number of connections yielded running due to hitting the memcached's -R limit.# TYPE memcached_connections_yielded_total countermemcached_connections_yielded_total 0# HELP memcached_current_bytes Current number of bytes used to store items.# TYPE memcached_current_bytes gaugememcached_current_bytes 2.57801625e+08# HELP memcached_current_connections Current number of open connections.# TYPE memcached_current_connections gaugememcached_current_connections 663# HELP memcached_current_items Current number of items stored by this instance.# TYPE memcached_current_items gaugememcached_current_items 1.117251e+06# HELP memcached_items_evicted_total Total number of valid items removed from cache to free memory for new items.# TYPE memcached_items_evicted_total countermemcached_items_evicted_total 0 如果看到输出的结果，那说明 memcached_exporter 已经收集到 memcached 的信息并将此暴露出来了。memcached 一些字段的含义 常见错误 配置错误 connection failed，注意地址 –memcached.address=192.168.21.16:11212 启动新的容器失败，地址端口占用，需要重启一下docker iptables 一般 reload， restart 会刷新 NAT 表，导致 docker 路由失败。这种情况需要重启 docker， docker 会在 NAT 表添加路由 Grafana 数据可视化grafana 官方文档，添加数据源，模板。prometheus function 函数在画图时非常重要12# 每分钟 command 的数量 sum(rate(memcached_commands_total&#123;instance=~"$node"&#125;[1m])) by (command)]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK 日志收集系统快速搭建]]></title>
    <url>%2Fpost%2Felk%2F</url>
    <content type="text"><![CDATA[ELK 官方文档 是一个分布式、可扩展、实时的搜索与数据分析引擎。目前我在工作中只用来收集 server 的 log, 开发锅锅们 debug 的好助手。 参考文章 腾讯云Elasticsearch Service 这个腾讯云的专栏非常的不错，请您一定要点开看一眼，总有你想要的。 ELK重难点总结和整体优化配置 安装设置单节点 ELK如果你想快速的搭建单节点 ELK, 那么使用 docker 方式肯定是你的最佳选择。使用三合一的镜像，文档详情注意：安装完 docker, 记得设置 mmap counts 大小至少 262144什么是 mmap1234567891011121314151617181920# 设置 mmap 命令# 临时添加法sysctl -w vm.max_map_count=262144 # 写入 sysctl.conf 文件里vim /etc/sysctl.confvm.max_map_count=262144 # 保存好文件执行以下命令sysctl -p# 安装 dockersudo yum install -y yum-utils device-mapper-persistent-data lvm2sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.reposudo yum install -y docker-cesudo systemctl start docker 单节点的机器，不必暴露 9200(Elasticsearch JSON interface) 和 9300(Elasticsearch transport interface) 端口。如果想在 docker 上暴露端口，用 -p 如果没有填写监听的地址，默认是 0.0.0.0 所有的网卡。建议还是写明确监听的地址，安全性更好。12-p 监听的IP:宿主机端口:容器内的端口-p 192.168.10.10:9300:9300 命令行启动一个 ELK12345sudo docker run -p 5601:5601 -p 5044:5044 \-v /data/elk-data:/var/lib/elasticsearch \-v /data/elk/logstash:/etc/logstash/conf.d \-it -e TZ="Asia/Singapore" -e ES_HEAP_SIZE="20g" \-e LS_HEAP_SIZE="10g" --name elk-ubuntu sebp/elk 将配置和数据挂载出来，即使 docker container 出现了问题。可以立即销毁再重启一个，服务受影响的时间很短。123456# 注意挂载出来的文件夹的权限问题chmod 755 /data/elk-data chmod 755 /data/elk/logstashchown -R root:root /data -v /data/elk-data:/var/lib/elasticsearch # 将 elasticsearch 存储的数据挂载出来，数据持久化。-v /data/elk/logstash:/etc/logstash/conf.d # 将 logstash 的配置文件挂载出来，方便在宿主机上修改。 elasticsearch 重要的参数调优 ES_HEAP_SIZE Elasticsearch will assign the entire heap specified in jvm.options via the Xms (minimum heap size) and Xmx (maximum heap size) settings. You should set these two settings to be equal to each other. Set Xmx and Xms to no more than 50% of your physical RAM.the exact threshold varies but is near 32 GB. the exact threshold varies but 26 GB is safe on most systems, but can be as large as 30 GB on some systems.利弊关系: The more heap available to Elasticsearch, the more memory it can use for its internal caches, but the less memory it leaves available for the operating system to use for the filesystem cache. Also, larger heaps can cause longer garbage collection pauses. LS_HEAP_SIZE 如果 heap size 过低，会导致 CPU 利用率到达瓶颈，造成 JVM 不断的回收垃圾。 不能设置 heap size 超过物理内存。 至少留 1G 给操作系统和其他的进程。 若是采用上述这个三合一的 docker 镜像，官方文档, 对于 ELK 的日志，处理的方式为 Note that ELK’s logs are rotated daily and are deleted after a week, using logrotate. You can change this behaviour by overwriting the elasticsearch, logstash and kibana files in /etc/logrotate.d 12# 每天的 6:25 会对日志进行分割压缩处理，此时对机器的 disk 有大量的 IO 工作，会导致 system load 上升。 25 6 * * * root test -x /usr/sbin/anacron || ( cd / &amp;&amp; run-parts --report /etc/cron.daily ) 非docker方式也是非常的简单，官方文档，或者是民间文档，其实也就是安装一个 JDK， 然后添加一个 repo 仓库。 filebeat 配置在 client 端，我们需要安装并且配置 filebeat 请参考Filebeat 模块与配置配置文件 filebeat.yml1234567891011121314151617181920filebeat.inputs:- type: log enabled: true paths: # 需要收集的日志 - /var/log/app/** ## ** need high versiob filebeat can support recursive fields: #需要添加的字段 host: "&#123;&#123;inventory_hostname&#125;&#125;" function: "xxx" multiline: # 多行匹配 match: after negate: true # pay attention the format pattern: '^\[[0-9]&#123;4&#125;-[0-9]&#123;2&#125;-[0-9]&#123;2&#125;' #\[ ignore_older: 24h clean_inactive: 72houtput.logstash: hosts: ["&#123;&#123;elk_server&#125;&#125;:25044"] # ssl: # certificate_authorities: ["/etc/filebeat/logstash.crt"] 批量部署 filebeat.yml 最好使用 ansible1234567891011121314151617181920212223242526272829---- hosts: all become: yes gather_facts: yes tasks: - name: stop filebeat service: name: filebeat state: stopped enabled: yes - name: upload filebeat.yml template: src: filebeat.yml dest: /etc/filebeat/filebeat.yml owner: root group: root mode: 0644 - name: remove file: #delete all files in this directory path: /var/lib/filebeat/registry state: absent - name: restart filebeat service: name: filebeat state: restarted enabled: yes 查看 filebeat output首先需要修改配置，将 filebeat 输出到本地的文件，输出的格式为 json.123456789101112131415161718filebeat.inputs:- type: log enabled: true paths: - /var/log/app/** fields: host: "x.x.x.x" region: "sg" multiline: match: after negate: true pattern: '^[0-9]&#123;4&#125;-[0-9]&#123;2&#125;-[0-9]&#123;2&#125;' ignore_older: 24h clean_inactive: 72houtput.file: path: "/home/feiyang" filename: feiyang.json 通过上述的配置，我们就可以在路径 /home/feiyang 下得到输出结果文件 feiyang.json 在这里需要注意的是，不同版本的 filebeat 输出结果的格式会有所不同，这会给 logstash 解析过滤造成一点点困难。下面举例说明 6.x 和 7.x filebeat 输出结果的不同 1234567891011121314151617181920212223&#123; "@timestamp": "2019-06-27T15:53:27.682Z", "@metadata": &#123; "beat": "filebeat", "type": "doc", "version": "6.4.2" &#125;, "fields": &#123; "host": "x.x.x.x", "region": "sg" &#125;, "host": &#123; "name": "x.x.x.x" &#125;, "beat": &#123; "name": "x.x.x.x", "hostname": "feiyang-localhost", "version": "6.4.2" &#125;, "offset": 1567983499, "message": "[2019-06-27T22:53:25.756327232][Info][@http.go.177] [48552188]request", "source": "/var/log/feiyang/scripts/all.log"&#125; 6.4 与 7.2 还是有很大的差异，在结构上。 1234567891011121314151617181920212223242526272829303132333435&#123; "@timestamp": "2019-06-27T15:41:42.991Z", "@metadata": &#123; "beat": "filebeat", "type": "_doc", "version": "7.2.0" &#125;, "agent": &#123; "id": "3a38567b-e6c3-4b5a-a420-f0dee3a3bec8", "version": "7.2.0", "type": "filebeat", "ephemeral_id": "b7e3c0b7-b460-4e43-a9af-6d36c25eece7", "hostname": "feiyang-localhost" &#125;, "log": &#123; "offset": 69132192, "file": &#123; "path": "/var/log/app/feiyang/scripts/info.log" &#125; &#125;, "message": "2019-06-27 22:41:25.312|WARNING|14186|Option|data|unrecognized|fields=set([u'id'])", "input": &#123; "type": "log" &#125;, "fields": &#123; "region": "sg", "host": "x.x.x.x" &#125;, "ecs": &#123; "version": "1.0.0" &#125;, "host": &#123; "name": "feiyang-localhost" &#125;&#125; 只需要配置logstash接下来，我们再来看一看 logstash.conf 记得看注释参考链接: SSL详情可参考 grok 正则捕获 grok插件语法介绍 logstash 配置语法 grok 内置 pattern Logstash详细记录 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081input &#123; beats &#123; port =&gt; 5044 #ssl =&gt; true #ssl_certificate =&gt; "/etc/logstash/logstash.crt" #ssl_key =&gt; "/etc/logstash/logstash.key"# 1. SSL详情可参考 &#125;&#125;# filter 模块主要是数据预处理，提取一些信息，方便 elasticsearch 好归类存储。# 2. grok 正则捕获# 3. grok插件语法介绍 # 4. logstash 配置语法 # 5. grok 内置 pattern filter &#123; grok &#123; match =&gt; &#123;"message" =&gt; "%&#123;EXIM_DATE:timestamp&#125;\|%&#123;LOGLEVEL:log_level&#125;\|%&#123;INT:pid&#125;\|%&#123;GREEDYDATA&#125;"&#125;# message 字段是 log 的内容，例如 2018-12-11 23:46:47.051|DEBUG|3491|helper.py:85|helper._save_to_cache|shop_session# 在这里我们提取出了 timestamp log_level pid，grok 有内置定义好的patterns: EXIM_DATE, EXIM_DATE, INT# GREEDYDATA 贪婪数据，代表任意字符都可以匹配 &#125;# 我们在 filebeat 里面添加了这个字段[fields][function]的话，那就会执行对应的 match 规则去匹配 path# source 字段就是 log 的来源路径，例如 /var/log/nginx/feiyang233.club.access.log# match 后我们就可以得到 path=feiyang233.club.access if [fields][function]=="nginx" &#123; grok &#123; match =&gt; &#123;"source" =&gt; "/var/log/nginx/%&#123;GREEDYDATA:path&#125;.log%&#123;GREEDYDATA&#125;"&#125; &#125; &#125; # 例如 ims 日志来源是 /var/log/ims_logic/debug.log# match 后我们就可以得到 path=ims_logic else if [fields][function]=="ims" &#123; grok &#123; match =&gt; &#123;"source" =&gt; "/var/log/%&#123;GREEDYDATA:path&#125;/%&#123;GREEDYDATA&#125;"&#125; &#125; &#125; else &#123; grok &#123; match =&gt; &#123;"source" =&gt; "/var/log/app/%&#123;GREEDYDATA:path&#125;/%&#123;GREEDYDATA&#125;"&#125; &#125; &#125;# filebeat 有定义 [fields][function] 时，我们就添加上这个字段，例如 QA if [fields][function] &#123; mutate &#123; add_field =&gt; &#123; "function" =&gt; "%&#123;[fields][function]&#125;" &#125; &#125; &#125; # 因为线上的机器更多，线上的我默认不在 filebeat 添加 function，所以 else 我就添加上 live else &#123; mutate &#123; add_field =&gt; &#123; "function" =&gt; "live" &#125; &#125; &#125;# 在之前 filter message 时，我们得到了 timestamp，这里我们修改一下格式，添加上时区。 date &#123; match =&gt; ["timestamp" , "yyyy-MM-dd HH:mm:ss Z"] target =&gt; "@timestamp" timezone =&gt; "Asia/Singapore" &#125;# 将之前获得的 path 替换其中的 / 替换为 - , 因为 elasticsearch index name 有要求# 例如 feiyang/test feiyang_test mutate &#123; gsub =&gt; ["path","/","-"] add_field =&gt; &#123;"host_ip" =&gt; "%&#123;[fields][host]&#125;"&#125; remove_field =&gt; ["tags","@version","offset","beat","fields","exim_year","exim_month","exim_day","exim_time","timestamp"] &#125;# remove_field 去掉一些多余的字段&#125;# 单节点 output 就在本机，也不需要 SSL, 但 index 的命名规则还是需要非常的注意output &#123; elasticsearch &#123; hosts =&gt; ["localhost:9200"] index =&gt; "sg-%&#123;function&#125;-%&#123;path&#125;-%&#123;+xxxx.ww&#125;"# sg-nginx-feiyang233.club.access-2019.13 ww代表周数 &#125;&#125; 最终的流程图如下所示index 的规则 参考链接 Lowercase only Cannot include \, /, *, ?, “, &lt;, &gt;, |, ` ` (space character), ,, # Indices prior to 7.0 could contain a colon (:), but that’s been deprecated and won’t be supported in 7.0+ Cannot start with -, _, + Cannot be . or .. Cannot be longer than 255 bytes (note it is bytes, so multi-byte characters will count towards the 255 limit faster) Kibana 简单的使用在搭建 ELK 时，暴露出来的 5601 端口就是 Kibana 的服务。访问 http://your_elk_ip:5601 安装设置集群 ELK 版本 6.7ELK 安装文档集群主要是高可用，多节点的 Elasticsearch 还可以扩容。本文中用的官方镜像 The base image is centos:7 Elasticsearch 多节点搭建官方安装文档 Elasticsearch1234567# 挂载出来的文件夹权限非常的重要mkdir -p /data/elk-data &amp;&amp; chmod 755 /data/elk-datachown -R root:root /data docker run -p WAN_IP:9200:9200 -p 10.66.236.116:9300:9300 \-v /data/elk-data:/usr/share/elasticsearch/data \--name feiy_elk \docker.elastic.co/elasticsearch/elasticsearch:6.7.0 接下来是修改配置文件 elasticsearch.yml1234567891011121314# Master 节点 node-1# 进入容器 docker exec -it [container_id] bash# docker exec -it 70ada825aae1 bash# vi /usr/share/elasticsearch/config/elasticsearch.ymlcluster.name: "feiy_elk"network.host: 0.0.0.0node.master: truenode.data: truenode.name: node-1network.publish_host: 10.66.236.116discovery.zen.ping.unicast.hosts: ["10.66.236.116:9300","10.66.236.118:9300","10.66.236.115:9300"]# exit# docker restart 70ada825aae1 123456789101112# slave 节点 node-2# 进入容器 docker exec -it [container_id] bash# vi /usr/share/elasticsearch/config/elasticsearch.ymlcluster.name: "feiy_elk"network.host: "0.0.0.0"node.name: node-2node.data: truenetwork.publish_host: 10.66.236.118discovery.zen.ping.unicast.hosts: ["10.66.236.116:9300","10.66.236.118:9300","10.66.236.115:9300"]# exit# docker restart 70ada825aae1 123456789101112# slave 节点 node-3# 进入容器 docker exec -it [container_id] bash# vi /usr/share/elasticsearch/config/elasticsearch.ymlcluster.name: "feiy_elk"network.host: "0.0.0.0"node.name: node-3node.data: truenetwork.publish_host: 10.66.236.115discovery.zen.ping.unicast.hosts: ["10.66.236.116:9300","10.66.236.118:9300","10.66.236.115:9300"]# exit# docker restart 70ada825aae1 检查集群节点个数，状态等123456789101112131415161718# curl http://wan_ip:9200/_cluster/health?pretty&#123; "cluster_name" : "feiy_elk", "status" : "green", "timed_out" : false, "number_of_nodes" : 3, "number_of_data_nodes" : 3, "active_primary_shards" : 9, "active_shards" : 18, "relocating_shards" : 0, "initializing_shards" : 0, "unassigned_shards" : 0, "delayed_unassigned_shards" : 0, "number_of_pending_tasks" : 0, "number_of_in_flight_fetch" : 0, "task_max_waiting_in_queue_millis" : 0, "active_shards_percent_as_number" : 100.0&#125; 最终结果图在 kibana 上可以看到集群状态 Kibana 搭建官方安装文档 Kibana123456# docker run --link YOUR_ELASTICSEARCH_CONTAINER_NAME_OR_ID:elasticsearch -p 5601:5601 &#123;docker-repo&#125;:&#123;version&#125;docker run -p 外网IP:5601:5601 --link elasticsearch容器的ID:elasticsearch docker.elastic.co/kibana/kibana:6.7.0# 注意的是 --link 官方其实并不推荐的，推荐的是 use user-defined networks https://docs.docker.com/network/links/# 测试不用 --link 也可以通。直接用容器的 IPdocker run -p 外网IP:5601:5601 docker.elastic.co/kibana/kibana:6.7.0 we recommend that you use user-defined networks to facilitate communication between two containers instead of using –link 1234567891011# vi /usr/share/kibana/config/kibana.yml# 需要把 hosts IP 改为 elasticsearch 容器的 IP# 我这里 elasticsearch 容器的 IP 是 172.17.0.2# 如何查看 docker inspect elasticsearch_IDserver.name: kibanaserver.host: "0.0.0.0"elasticsearch.hosts: [ "http://172.17.0.2:9200" ]xpack.monitoring.ui.container.elasticsearch.enabled: true# 退出容器并重启docker restart [container_ID] Logstash 搭建官方安装文档 Logstash1234# docker -d 以后台的方式启动容器 --name 参数显式地为容器命名docker run -p 5044:5044 -d --name test_logstash docker.elastic.co/logstash/logstash:6.7.0# 也可以指定网卡，监听在内网或者外网 监听在内网 192.168.1.2docker run -p 192.168.1.2:5044:5044 -d --name test_logstash docker.elastic.co/logstash/logstash:6.7.0 1234# vi /usr/share/logstash/pipeline/logstash.conf# 配置详情请参考下面的链接,记得 output hosts IP 指向 Elasticsearch 的 IP# Elasticsearch 的默认端口是9200，在下面的配置中可以省略。hosts =&gt; ["IP Address 1:port1", "IP Address 2:port2", "IP Address 3"] logstash 过滤规则 见上文的配置和 grok 语法规则123456# vi /usr/share/logstash/config/logstash.yml# 需要把 url 改为 elasticsearch master 节点的 IPhttp.host: "0.0.0.0"xpack.monitoring.elasticsearch.url: http://elasticsearch_master_IP:9200node.name: "feiy"pipeline.workers: 24 # same with cores 改完配置 exit 从容器里退出到宿主机，然后重启这个容器。更多配置详情，参见官方文档1234# 如何查看 container_IDdocker ps -adocker restart [container_ID] 容灾测试我们把当前的 master 节点 node-1 关机，通过 kibana 看看集群的状态是怎样变化的。当前集群的状态变成了黄色，因为还有 3 个 Unassigned Shards。颜色含义请参考官方文档，再过一会发现集群状态变成了绿色。 kibana 控制台 ConsoleQuick intro to the UIThe Console UI is split into two panes: an editor pane (left) and a response pane (right). Use the editor to type requests and submit them to Elasticsearch. The results will be displayed in the response pane on the right side. Console understands requests in a compact format, similar to cURL:12345678# index a docPUT index/type/1&#123; "body": "here"&#125;# and get it ...GET index/type/1 While typing a request, Console will make suggestions which you can then accept by hitting Enter/Tab. These suggestions are made based on the request structure as well as your indices and types. A few quick tips, while I have your attention Submit requests to ES using the green triangle button. Use the wrench menu for other useful things. You can paste requests in cURL format and they will be translated to the Console syntax. You can resize the editor and output panes by dragging the separator between them. Study the keyboard shortcuts under the Help button. Good stuff in there! Console 常用的命令Kibana 控制台ELK技术栈中的那些查询语法1234567891011121314151617181920212223242526272829303132333435363738394041424344GET _search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;&#125;GET /_cat/health?vGET /_cat/nodes?vGET /_cluster/allocation/explainGET /_cluster/stateGET /_cat/thread_pool?vGET /_cat/indices?health=red&amp;vGET /_cat/indices?v#将当前所有的 index 的 replicas 设置为 0PUT /*/_settings&#123; &quot;index&quot; : &#123; &quot;number_of_replicas&quot; : 0, &quot;refresh_interval&quot;: &quot;30s&quot; &#125;&#125;GET /_template# 在单节点的时候，不需要备份，所以将 replicas 设置为 0PUT _template/app-logstash&#123; &quot;index_patterns&quot;: [&quot;app-*&quot;], &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 3, &quot;number_of_replicas&quot;: 0, &quot;refresh_interval&quot;: &quot;30s&quot; &#125;&#125; Elasticsearch 数据迁移Elasticsearch 数据迁移官方文档感觉不是很详细。容器化的数据迁移，我太菜用 reindex 失败了，snapshot 也凉凉。最后是用一个开源工具 An Elasticsearch Migration Tool 进行数据迁移的。 123wget https://github.com/medcl/esm-abandoned/releases/download/v0.4.2/linux64.tar.gztar -xzvf linux64.tar.gz./esm -s http://127.0.0.1:9200 -d http://192.168.21.55:9200 -x index_name -w=5 -b=10 -c 10000 --copy_settings --copy_mappings --force --refresh Nginx 代理转发因为有时候 docker 重启，iptables restart 也会刷新，所以导致了我们的限制规则会被更改，出现安全问题。这是由于 docker 的网络隔离基于 iptable 实现造成的问题。为了避免这个安全问题，我们可以在启动 docker 时，就只监听在内网，或者本地 127.0.0.1 然后通过 nginx 转发。12345678910111213141516171819202122232425# cat kibana.confserver &#123; listen 25601; server_name x.x.x.x; access_log /var/log/nginx/kibana.access.log; error_log /var/log/nginx/kibana.error.log; location / &#123; allow x.x.x.x; allow x.x.x.x; deny all; proxy_http_version 1.1; proxy_buffer_size 64k; proxy_buffers 32 32k; proxy_busy_buffers_size 128k; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:5601; &#125;&#125; ! 这里需要注意的是， iptable filter 表 INPUT 链 有没有阻挡 172.17.0.0/16 docker 默认的网段。是否阻挡了 25601 这个端口。 踩过的坑 iptables 防不住。需要看上一篇博客里的 iptable 问题。或者监听在内网，用 Nginx 代理转发。 elk 网络问题 elk node discovery.type=single-node 在测试单点时可用，搭建集群时不能设置这个环境变量，详情见官方文档 ELK的一次吞吐量优化 filebeat 版本过低导致 recursive glob patterns ** 不可用用 ansible 升级 filebeat 123456789101112131415161718192021222324252627282930313233---- hosts: all become: yes gather_facts: yes tasks: - name: upload filebeat.repo copy: src: elasticsearch.repo dest: /etc/yum.repos.d/elasticsearch.repo owner: root group: root mode: 0644 - name: install the latest version of filebeat yum: name: filebeat state: latest - name: restart filebeat service: name: filebeat state: restarted enabled: yes # elasticsearch.repo[elasticsearch-6.x]name=Elasticsearch repository for 6.x packagesbaseurl=https://artifacts.elastic.co/packages/6.x/yumgpgcheck=1gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearchenabled=1autorefresh=1type=rpm-md filebeat 7.x 与 6.x 不兼容问题. 关键字变化很大, 比如说 “sorce” 变为了 [log][file][path]]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>elk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub-Hexo-NexT 免费搭建自己的博客]]></title>
    <url>%2Fpost%2Fhexo-blog%2F</url>
    <content type="text"><![CDATA[关于写博客2018 年我在 GitHub 上看到强哥的博客，当时为之心动然后 Fork 了那个 repository。后来搬砖沦为社会人就断更了，在工作之后看到奥哥的博客，在他的安利之下，把之前的 Jekyll 的博客换成如今的 Hexo-NexT，打算记录下工作的点滴，学习的心得。一是分享，二是方便自己回顾和查阅。 GitHub如果没有 GitHub 账号，需要去官网 https://github.com/ 注册一个账号。账号注册好之后，需要创建一个 repository，名称格式为 xxx.github.io 例如我的 GitHub 名称为 fainyang, 浏览器显示的 URL 为 https://github.com/fainyang 那么我新建的 repository 就是 fainyang.github.io 申请完账号，创建了 repository 之后，下一步就是在自己的电脑上安装 Hexo。 HexoHexo——快速、简洁且高效的博客框架。官网 https://hexo.io/zh-cn/ 文档还有视频讲解如何安装 安装前提在安装 Hexo 之前，需要安装 Git 与 Node.js 请参考 这里 开始安装12345npm install hexo-cli -g npm install hexo --savehexo init &lt;folder&gt; # &lt;folder&gt; 自己取个文件夹名字cd &lt;folder&gt; # 移动到 &lt;folder&gt; 文件夹，不清楚当前路径，可以执行 Mac:pwd Windows: chdirnpm install #feiy-mac:Coding feiy$ pwd /Users/feiy/Coding 新建完成后，指定文件夹的目录如下：12345678.├── _config.yml #站点配置文件,主要就是修改这个文件├── package.json├── scaffolds #模板文件夹├── source #存放文章，图片的文件夹| ├── _drafts| └── _posts└── themes #主题文件夹，等会下载 NexT 主题 这是我的 _config.yml 配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596# Hexo Configuration## Docs: https://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Sitetitle: feiyang's blog subtitle: 费洋的博客description: 佛系咸鱼keywords:author: feiyanglanguage: zh-CN #网址的显示语言timezone:# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: https://fainyang.github.io #需要修改为自己的网址enforce_ssl: fainyang.github.ioroot: /permalink: post/:title/permalink_defaults:# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: # Home page setting# path: Root path for your blogs index page. (default = '')# per_page: Posts displayed per page. (0 = disable pagination)# order_by: Posts order. (Order by date descending by default)index_generator: path: '' per_page: 10 order_by: -date # Category &amp; Tagdefault_category: uncategorizedcategory_map: tag_map: # Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: next# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: https://github.com/fainyang/fainyang.github.io.git #部署上传的地址，需要修改为自己的 branch: master message: new hexo_blog # Othersarchive_generator: per_page: 10 yearly: true monthly: truetag_generator: per_page: 10 Hexo 常用命令官网详细的介绍 https://hexo.io/zh-cn/docs/commands 123456命令缩写hexo n "文章标题" == hexo new "文章标题" #新建文章hexo p == hexo publishhexo g == hexo generate #生成hexo s == hexo server #启动服务预览hexo d == hexo deploy #部署 本地运行网站123hexo s # 当前路径要在之前创建的 hexo init &lt;folder&gt; 这个 &lt;folder&gt; 下INFO Start processingINFO Hexo is running at http://localhost:4000 . Press Ctrl+C to stop. 在浏览器输入 http://localhost:4000 就可以看到初始的网站 NexTElegant Theme for Hexo——精于心，简于形。 官网 http://theme-next.iissnan.com/ 安装 Next1234# 当前路径要在之前创建的 hexo init &lt;folder&gt; 这个 &lt;folder&gt; 下 # 查看当前路径 Mac:pwd Windows: chdircd &lt;folder&gt;git clone https://github.com/theme-next/hexo-theme-next themes/next git clone 完成后，指定文件夹的目录如下：1234567891011.├── _config.yml #站点配置文件，主要就是修改这个文件├── package.json├── scaffolds #模板文件夹├── source #存放文章，图片的文件夹| ├── _drafts| └── _posts└── themes #主题文件夹，等会下载 NexT 主题 ├── landscape └── next └── _config.yml #主题配置文件，修改博客主题样式等 主题配置文件 _config.yml12345678910111213# 菜单显示项menu: home: / || home about: /about/ || user tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive# Schemes 主题选择，我用的是 Gemini#scheme: Muse#scheme: Mist#scheme: Piscesscheme: Gemini 此时可以在本地预览一下运行命令 hexo s 部署到 GitHub部署前，需要修改配置文件里面的 git 地址12345deploy: type: git repo: https://github.com/yourname/yourname.github.io.git #部署上传的地址，需要修改为自己的 branch: master message: new hexo_blog 修改好 _config.yml 里的 deploy 模块后，就可以开始进行部署，上传到 GitHub1234npm install hexo-deployer-git --savehexo cleanhexo generatehexo deploy 第一次部署需要输入自己的 GitHub 账号和密码。后面更新部署时就不需要再次输入密码了。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188feiy-mac:fainyang.github.io feiy$ hexo clean #清除缓存INFO Deleted database.INFO Deleted public folder.feiy-mac:fainyang.github.io feiy$ hexo generate #生成文件INFO Start processingINFO Files loaded in 902 msINFO Generated: sitemap.xmlINFO Generated: atom.xmlINFO Generated: index.htmlINFO Generated: tags/index.htmlINFO Generated: categories/index.htmlINFO Generated: archives/index.htmlINFO Generated: about/index.htmlINFO Generated: img/combination1.pngINFO Generated: images/algolia_logo.svgINFO Generated: img/combination2.pngINFO Generated: img/404-southpark.jpgINFO Generated: img/favicon.icoINFO Generated: img/gay.jpegINFO Generated: images/apple-touch-icon-next.pngINFO Generated: img/old_driver.jpgINFO Generated: img/qq-qrcode.pngINFO Generated: img/zjxc.jpgINFO Generated: images/cc-by-nc-nd.svgINFO Generated: images/avatar.gifINFO Generated: images/cc-by-nc-sa.svgINFO Generated: images/cc-by-nc.svgINFO Generated: images/cc-by-sa.svgINFO Generated: images/cc-by-nd.svgINFO Generated: images/cc-by.svgINFO Generated: images/favicon.icoINFO Generated: images/quote-l.svgINFO Generated: images/cc-zero.svgINFO Generated: images/loading.gifINFO Generated: images/logo.svgINFO Generated: images/searchicon.pngINFO Generated: images/favicon-16x16-next.pngINFO Generated: images/placeholder.gifINFO Generated: images/favicon-32x32-next.pngINFO Generated: images/quote-r.svgINFO Generated: images/feiy.gifINFO Generated: archives/2019/03/index.htmlINFO Generated: archives/2018/02/index.htmlINFO Generated: post/hexo-blog/index.htmlINFO Generated: img/work/6.jpgINFO Generated: archives/2018/08/index.htmlINFO Generated: categories/学习/index.htmlINFO Generated: archives/2018/11/index.htmlINFO Generated: archives/2018/07/index.htmlINFO Generated: img/robot/run.pngINFO Generated: tags/python/index.htmlINFO Generated: categories/生活/index.htmlINFO Generated: tags/hexo/index.htmlINFO Generated: tags/工作/index.htmlINFO Generated: archives/2018/04/index.htmlINFO Generated: archives/2018/03/index.htmlINFO Generated: tags/links/index.htmlINFO Generated: post/Canteen/index.htmlINFO Generated: tags/NUS/index.htmlINFO Generated: img/2019/github.pngINFO Generated: post/Onboarding/index.htmlINFO Generated: post/Combination/index.htmlINFO Generated: post/Robot/index.htmlINFO Generated: post/blog/index.htmlINFO Generated: post/Master/index.htmlINFO Generated: post/links/index.htmlINFO Generated: post/timestampdiff/index.htmlINFO Generated: img/time3.pngINFO Generated: img/start.jpgINFO Generated: img/robot/tencent.pngINFO Generated: img/work/8.JPGINFO Generated: img/work/7.JPGINFO Generated: img/avatar-icon.jpgINFO Generated: img/time1.pngINFO Generated: img/wx-qrcode.pngINFO Generated: archives/2018/index.htmlINFO Generated: archives/2019/index.htmlINFO Generated: img/146228364162795.jpgINFO Generated: lib/font-awesome/HELP-US-OUT.txtINFO Generated: css/main.cssINFO Generated: img/canteen/bird.jpgINFO Generated: img/combination3.pngINFO Generated: img/time4.pngINFO Generated: img/path.jpgINFO Generated: img/time2.pngINFO Generated: img/work/10.JPGINFO Generated: img/work/5.JPGINFO Generated: img/work/13.JPGINFO Generated: img/work/2.JPGINFO Generated: img/work/1.JPGINFO Generated: lib/font-awesome/bower.jsonINFO Generated: img/robot/ditou.jpgINFO Generated: img/canteen/contact.pngINFO Generated: img/robot/happy.jpgINFO Generated: img/robot/poor.jpegINFO Generated: img/robot/miaohui.jpgINFO Generated: img/robot/qidai.jpegINFO Generated: img/robot/python.pngINFO Generated: img/robot/tuling.pngINFO Generated: img/canteen/B.pngINFO Generated: img/robot/dalao.pngINFO Generated: lib/velocity/velocity.ui.min.jsINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.woff2INFO Generated: img/robot/result3.jpegINFO Generated: img/canteen/F-319.pngINFO Generated: img/canteen/F-320.pngINFO Generated: img/robot/result1.jpegINFO Generated: img/work/9.JPGINFO Generated: img/canteen/wen.pngINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.woffINFO Generated: img/canteen/E1.pngINFO Generated: lib/velocity/velocity.ui.jsINFO Generated: lib/velocity/velocity.min.jsINFO Generated: img/canteen/E-322.pngINFO Generated: img/canteen/F-321.pngINFO Generated: img/canteen/F-322.pngINFO Generated: img/canteen/F-323.pngINFO Generated: img/canteen/Y-320.pngINFO Generated: img/canteen/Y-321.pngINFO Generated: img/canteen/Y-322.pngINFO Generated: img/work/12.JPGINFO Generated: img/robot/result2.jpegINFO Generated: img/work/4.JPGINFO Generated: img/canteen/E-319.pngINFO Generated: js/src/algolia-search.jsINFO Generated: lib/font-awesome/css/font-awesome.css.mapINFO Generated: img/issue.pngINFO Generated: img/combination4.pngINFO Generated: img/canteen/E-323.pngINFO Generated: img/work/3.JPGINFO Generated: img/canteen/Y-319.pngINFO Generated: img/canteen/table.pngINFO Generated: img/work/11.JPGINFO Generated: img/work/15.JPGINFO Generated: js/src/affix.jsINFO Generated: js/src/exturl.jsINFO Generated: js/src/next-boot.jsINFO Generated: js/src/scrollspy.jsINFO Generated: js/src/js.cookie.jsINFO Generated: js/src/post-details.jsINFO Generated: js/src/scroll-cookie.jsINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.eotINFO Generated: img/canteen/Y-323.pngINFO Generated: img/canteen/E-321.pngINFO Generated: img/canteen/E-320.pngINFO Generated: lib/font-awesome/css/font-awesome.min.cssINFO Generated: lib/font-awesome/css/font-awesome.cssINFO Generated: js/src/motion.jsINFO Generated: js/src/utils.jsINFO Generated: js/src/schemes/pisces.jsINFO Generated: img/work/16.JPGINFO Generated: js/src/schemes/muse.jsINFO Generated: img/work/14.JPGINFO Generated: lib/jquery/index.jsINFO Generated: img/install-steps.gifINFO Generated: lib/velocity/velocity.jsINFO Generated: img/work/17.JPGINFO Generated: img/work/18.jpgINFO 152 files generated in 1.86 sfeiy-mac:fainyang.github.io feiy$ hexo deploy #部署到 GitHubINFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...INFO Copying files from extend dirs...[master f55c4d1] new hexo_blog 34 files changed, 8859 insertions(+), 150 deletions(-) create mode 100644 archives/2019/03/index.html create mode 100644 archives/2019/index.html create mode 100644 categories/index.html create mode 100644 categories/学习/index.html create mode 100644 categories/生活/index.html create mode 100644 img/2019/github.png create mode 100644 post/hexo-blog/index.html create mode 100644 tags/NUS/index.html create mode 100644 tags/hexo/index.html rename tags/&#123;life =&gt; links&#125;/index.html (87%) create mode 100644 tags/工作/index.htmlEnumerating objects: 114, done.Counting objects: 100% (114/114), done.Delta compression using up to 4 threadsCompressing objects: 100% (43/43), done.Writing objects: 100% (69/69), 97.73 KiB | 3.62 MiB/s, done.Total 69 (delta 33), reused 0 (delta 0)remote: Resolving deltas: 100% (33/33), completed with 17 local objects.To https://github.com/fainyang/fainyang.github.io.git 2b7a9ca..f55c4d1 HEAD -&gt; masterBranch 'master' set up to track remote branch 'master' from 'https://github.com/fainyang/fainyang.github.io.git'.INFO Deploy done: git 在浏览器输入: yourname.github.io 如果看到博客页面那就大功告成。如果有错误的话，在 GitHub repository Setting 里的 GitHub Pages 可以看到错误信息。 图片管理奥哥推荐的一个非常好用的图片管理工具 PicGo 图片上传+管理新体验。 踩过的一些坑 在添加标签和分类的时候，当在source下面创建了文件夹的 index.md 这个文件一定要添加相关的 type. 例如 type: “categories”, type: “tags”. 添加搜索功能时，一直转圈加载不出来。是因为自己写的文章中存在不可见字符：一个backspace的字符。 详情可以参考： 一&nbsp; 二]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实用链接分享]]></title>
    <url>%2Fpost%2Flinks%2F</url>
    <content type="text"><![CDATA[站在大佬们的肩膀上工作，学习，健身。 其实我蛮担心自己的发际线 运维博客 朱双印博客 iptables, ansible, zabbix 都很不错 骏马金龙 rsync, LVS, nginx, zooKeeper 金步国作品集 Linux HelloDog 大佬同事奥哥的博客 实用文档 ansible 批量操作的好帮手 zabbix 实时监控了解一下 ELK 收集过滤检索神器 Docker 方便快速的容器 Kubernetes DevOps 玩转容器部署 学习一个 慕课网 程序员的梦工厂 菜鸟教程 学的不仅是技术，更是梦想 w3school Web 技术教程 提高生产力 任务管理看板 Trello 免费无广告 好书推荐 强哥 安利的 设计数据密集型应用 这或许是东半球分析十大排序算法最好的一篇文章]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>links</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[新加坡留学分享]]></title>
    <url>%2Fpost%2FMaster%2F</url>
    <content type="text"><![CDATA[为什么要留学这篇博客主要分享我的新加坡水硕留学经历，希望能对你有一点点帮助。 留学的优势： 时间短，新加坡的授课型 Master 一年就读完。因为 EE 学院是按照学期收学费的，最快一年修完。大家当然都早点修完省学费。当国内同届的同学毕业时，你已经是有 2年工作经验的初级混子了。 毕业容易，毕业要求是修满 10 门课，没有导师。轻轻松松考完 10 门课混水硕文凭，考试是按照正态分布评分的，想挂科太难了。当然，你也可以选一个project跟着导师做一年项目，一个project抵两门课的学分。不要抱太大的期望，关键还是靠自学。比如我自己就选了项目，认识一个不错的导师，受益良多。 读博容易， 读完一年硕士，再去申请博士，比本科毕业申请直博容易太多，而且有机会面对面和导师交流，提前了解实验室的情况。我一届的 master 同学，想读博的，最后硕士毕业都梦想成真读博了。 长见识，肉身翻墙出来看看世界之大，结识外国的朋友们，体验东南亚文化，然后你就知道还是祖国安逸，我多么想念四川美食。 当跳板，如果想出国工作，那么出国读书无疑是最好的一条路，毕业后留下来找工作。当然也有 Master 毕业再去美国读博的。 海龟光环，像华为的海外招聘回国工作的起薪比国内稍高一点。还有一个巨大的优势就是走海外选调生考公务员竞争小。 出游方便，因为新加坡是东南亚的经济中心，飞东南亚的航班又多又便宜。读书期间假期飞东南亚各国旅游，马来西亚，泰国，越南，印度尼西亚，菲律宾都非常方便。例如去年 recess week 我去槟城往返一共才 350 人民币的机票。 留学的劣势： 花费贵，硕士读下来至少 18 万人民币的学费，每个月生活费至少五千人民币。新加坡留学贷款，可以在学校里贷款 8 千新币，相当于 4 万人民币，利息很低，工作以后慢慢还。 压力大，虽然是水硕，但是全英文环境最开始还是有点不适应。如果选了 project，还要做项目写论文答辩。相当于把国内三年完成的事情全部压缩到一年内完成，十分的匆忙。 水土不服，这个因人而异。来新加坡读书有的同学瘦了十多斤，有的冒痘痘，有的脱发。但大家相同的感受就是太晒了（其实温度还好，最高 35° 左右）。 什么样的人适合来新加坡留学 安全第一，新加坡治安在世界数一数二了。在大学里去食堂吃饭把电脑，手机放图书馆桌上很安全。在我读书的一年里，没有听说中国留学生有谁遇到失窃的。晚上大街上走也很安全的。（相比于犯罪分子，倒不如小心野生动物，蛇，蜥蜴那些） 英语差的人，比如我自己。其实新加坡留学一年生活中，除了上课，和导师，外国人交流用英文。平时都用中文，本地华人的中文也非常好。（其实这也是缺点，读书一年，发现自己的口语没有怎么提高） 怕离家太远。新加坡回国非常快，飞中国南方的城市大约4个小时，而且往返机票（非节假日）大约两千多人民币。 负担不起美国留学，又想出来看看的人，比如我自己。新加坡的学费和生活费相对便宜。 国内考研失败，但想继续读研的同学，出国读研肯定比二战的压力小太多了。国内考研每年一次，国外读研申请分两次，有秋季和春季。 留学的条件就三点：学科成绩，英语成绩，留学费用。 学科成绩：NUS NTU 两所学校 Master 招生大部分都是 985，211的毕业生。NUS ECE学院基本上要本科成绩平均分85+，NTU EEE学院要求会稍微低一点。 英语成绩：NUS 雅思最低 6 分，NTU 雅思最低 6.5 分 但最好 NUS 也是6.5 分。 这样的话开学就不用额外再上英语课。雅思的备考，可以报班，也可以自学。推荐APP: 雅思哥，小站雅思。个人的建议是英语不好的同学还是花钱报班吧，老师带着入门快点。 留学费用：今年2018 NUS Master 入学的费用国际留学生一共是36,750新币。 以前是有 government-subsidised graduate programmes 补贴的(减免一半的学费)，但是从明年 2019 开始就没有了。读下来学费加生活费一年至少18+7=25万。申请的时候还需要银行开具存款证明，每年的标准不同，大概在人民币 15 万左右。 如何申请 找中介，适用于时间匆忙，想花钱省事的同学们。中介费大概在2万左右，中介老师会帮你写简历，文书，推荐信，邮寄申请材料等。推荐找大机构知名的中介，私人中介小心被坑。就算找了中介，自己还是要上点心，看看中介帮写的材料，注意申请的截止时间等。 DIY，适用于时间充足，想省钱的同学。作为 DIY 过来人，新加坡和香港的申请都比较简单，申请的 requirement 网上都有，截止时间也都写的明明白白，只是需要自己细心的去寻找。如果有学长学姐指导，老司机带是最稳的。要自己 DIY 记得让父母申请一张 Visa 或者 Master Card，因为申请缴费的时候是不能用银联卡的。寄托论坛上也有前辈们分享如何申请的。 申请所需资料：本科成绩单，本科在读证明，语言成绩单(雅思或托福)，个人简历，2 封推荐信，个人陈述（申请的理由，规划那些），银行存款证明。 申请分秋季入学和春季入学。秋季是每年的一月开始申请，先在学校官网上申请，最后把所需的资料邮寄到学校，顺丰到新加坡只需 3 天。 入学前准备秋季入学是每年的五月初发 offer，寄托论坛也有 offer榜，可以看看其他人的录取情况。很多人都会收到两所学校的录取，那么上 NUS 还是选 NTU 呢？首先当然看看自己所读的专业哪个学校好啦，其实两所学校都差不多。NUS 在本地人眼里更好一点，离城里近，但申请不到宿舍，ECE 学院选课自由，有点像国内的按大类招生。 NTU 坐落在郊区，能申到宿舍。食堂十分的优秀，比 NUS 好吃。环境优美，有野猪等野生动物出没。 在收到 offer 后最重要的一件事情就是：申请宿舍，NUS Master 申请宿舍成功率低，因为 NUS 地方小宿舍少，几乎在 NUS 读 Master 的同学们都是在外面租房子，一般都是六个人租一整套三室一厅，两个人 share 一间房。租房子必须找中介，Property Guru 和 99co新加坡本地发布平台，房源多。查找 NUS 周围的房源，然后联系中介看房，最后签合同。最近还有一个不错的小程序叫：小坡岛新加坡租房。一般 share 住房租人均在 450-600 新币/月，水电气网大约 50 新/月。 NTU 就很优秀了，人人都能申请到宿舍。宿舍的配套设施很完善，厨房，洗衣房，自习室，健身房，食堂都有。宿舍价格根据宿舍类型定价 300-600 新币/月。 把住的地方提前搞定后，等学校帮忙办理好学生签证，接下来就是收拾行李准备留学啦。 新加坡的手机网络，国内全网通手机就 OK，最好提前在淘宝买一张 3天无限流量卡。等安顿好了，再去 711、Cheers、手机店买本地电话卡。 必备的APP: Grab（东南亚滴滴，打车方便，可以绑定支付宝付款）SG Buses (坐公交车必备，查询等车时间) Google Maps (出国当然用谷歌) 银行卡：推荐办理在境外取现不收取手续费的银联卡。比如华夏银行，成都银行金卡等。 机票：廉价航空没有行李额！留学生过来读书肯定都带了箱子，等到机场再买行李额要贵哭。我建议是不要买廉价航空，川航、国航都是两件行李额，南航是一件。 新加坡全年夏天，衣服最多带一件外套抵御教室里寒冷的空调。这面的优衣库，H&amp;M 价格和国内差不多。 再安利一下同事奥哥写的新加坡生活指南，网站有可能被墙了。 学生生活 报到：到新加坡安顿好以后，就去学校注册报到，然后就是校医院体检（主要检查肺结核和 HIV ）。接下来还有半个月开学，可以出去逛一逛，熟悉一下环境。 选课：开学之前要网上选课，这个根据自己的爱好和学长学姐的建议，不要踩雷。可以选择 10门课，也可以选择 8门课 + 1个项目。 上课：时间都是在晚上（本科课程在白天，NUS 可以跨选本科的课程，NTU 不能选本科课程），因为有非全日制的同学（人家白天要上班的），一周最多也就5节课。 每周都会有作业，有的 project 还需要小组组队完成。 编程作业 GitHub了解一下，说不定有答案。 考试：在选课时就能看到期末考试日期，所以可以提前买回家的机票呀。考试时间一般是 2-2.5 小时，有开卷，闭卷，一页纸。评分按正态分布，想挂科和得 A+ 一样的困难。 混个水硕还是非常容易的。 项目： 选一个导师跟着做一年。NUS 最后要写论文答辩，NTU 写论文不答辩。确认过眼神，遇上对的老师收获巨大，选错就以泪洗面！ 毕业要求：总学分平均绩点大于3.0， 3.0 我上我也行！（满绩是5.0 允许单科低于3.0 只要不是 F 就行，一般缺考才会得 F ） 就业去向：留下来的大多去了半导体和互联网公司，回国大部分都去互联网公司，少部分走海外选调生当公务员。 2019 年，我刚刚成功内推一个我电 14 级的通信学妹入职我司。 继续读博： 其实有很大比例的同学是把新加坡水硕当跳板，硕士毕业后去 NUS NTU 读博，还有去美国读博的。先读了 master 再读 PhD 比较容易，我认识的同学中，想读 PhD 的最终都梦想成真，只是有的老师手里名额多，硕士毕业马上入学 PhD。有的导师名额少，需要先做 RA 排队等待。 我的学生日常：白天早起去学校图书馆自习，起晚了太阳晒呀。白天自习，晚上上课。每周和导师一次 meeting 汇报情况。周末做作业、项目，偶尔出去聚餐。 如今回想起来，白天不上课应该去找一个实习做一做的，这样有助于就业。 第二学期就比较忙一点，因为要找工作。每学期学校都有招聘会，不容错过。其他找工作的途径，在我上一篇博客咸鱼入海Sea里有。新加坡半导体和互联网就业相对容易，新加坡工程系毕业的 Master 起薪大概在 3600-4500 新币/月。 新加坡个人所得税很低。Master 刚毕业一年大概就交 600 新的税。 更新：2018 年，工作半年我自己交的税是 72 新币。在新加坡上班，目前我自己的感受：互联网比国内轻松一点，很少加班，周末双休。 半导体上班同学的感受：Micron上班 8小时，加班有工资美滋滋。 Liteon 同学感觉就像在国企上班一样，每天 5:30pm 下班，闲的都想回学校再读一个part-time Phd.如果能有幸进入 全球大厂例如 Facebook（包三餐，早9:30晚6），Google，Apple,或者新加坡的国企（早10晚6），可能真的会乐不思蜀了。 曾经的我，以为出国遥不可及，担心给家里带来巨大的负担。如今看来一切付出都是值得的，至少在我的留学圈子里，没有哪个同学后悔出来看一看。很惭愧，只做了一点微小的贡献。 最后祝大家前程似锦，梦想成真]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>NUS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[咸鱼入海Sea]]></title>
    <url>%2Fpost%2FOnboarding%2F</url>
    <content type="text"><![CDATA[求职经历今年研究生毕业，在经历了一波三折的找工作之后。我这个咸鱼最终也找到了一份心仪的工作，在sea公司做Operation Enginner. 我是在春季的校园招聘会上投的简历，今天还翻到了曾经在招聘会上领取的资料 一般找工作的途径： 找学长学姐内推 通过校园招聘会现场投简历 公司官网在线投简历 招聘网站，像Monster，Glassdoor，Jobstreet. 如果是NUS学生，还可以通过NUS校园求职网站 总的来说，有内推是最好的，响应速度快，简历不容易被刷。其次是校园招聘会和校园求职网，都是校招，难度也低。 公司官网也可以，但要自己去一家家的找。专门的求职网站选择就很多，但自己要耐心的筛选（太多不知道的公司了，我曾经就被一家小作坊坑了，去面试的时候被那工作环境震惊）.心得体会，应届生进入社会第一课：虚心好学，接受自己的平庸。早做准备，明白自己想干什么。举例子，如果打算未来从事某一项工作，那就去看看网上这份工作的描述，对求职者的要求是什么。（PS:简历也是很重要的一部分）祝大家求职顺利! 公司介绍Sea是东南亚的一家互联网公司，旗下有garena（东南亚游戏代理：王者荣耀，英雄联盟等），shopee（东南亚的电商），airpay（想做东南亚的支付宝）。 公司的员工都很年轻，几乎都是美丽小姐姐、帅气小哥哥们，超级nice的。公司的环境也相当的棒： 入职大礼包 还有互联网公司标配的Mac Pro 两个戴尔 U2417H 显示器 公司福利 每个月还有两次马杀鸡按摩 还有最受好评的小卖部，视频链接在这里 早上还有一盒水果和晚上的工作餐 环境福利虽好，但每晚大概吃完饭都八点了，搬砖狗住！ 谨以此文记录咸鱼开启职场生活公司的职位在这里，需要内推的欢迎联系我email: fainyang@foxmail.com]]></content>
      <tags>
        <tag>工作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NUS食堂排队指南]]></title>
    <url>%2Fpost%2FCanteen%2F</url>
    <content type="text"><![CDATA[人生苦短，珍惜时间这个其实是我读研在 NUS 跟着导师做的项目，自认为还是比较有趣的。在食堂吃饭，最怕长队漫漫，还有狗粮作伴。人生很多事情因为慢慢等待就错过了，本来打算去食堂吃某一样菜，却因为漫长的排队等待而望而却步。所以嘛，年轻人要想少留遗憾，就要主动出击，爱要提前行动呀！ 本文主要基于WiFi历史数据，分析NUS 工学院、文学院、YIH食堂的规律（本来最初还计划有computing食堂的，奈何系统上没有相关的信息记录）。用数据说话，分析每天食堂的拥挤时段给大家参考，以便大家减少排队时间，提高用餐体验。 假设每个用户只有一个设备（在食堂用电脑的也比较少），并且在校园内大多数人都会打开WiFi。我们根据WiFi的连接情况，可以间接的判断人群密度，停留时间，流入流出速率。人群密度只需要统计每分钟连接WiFi的设备数即可。停留时间是由思科WiFi系统记录设备第一次连接WiFi的时间和当前时间作差得出，当设备离线超过15min系统会刷新first located time。流入流出速率则是比较前后两分钟mac address的不同来判断得出。 首先举个例子好啦WiFi原始数据如下图所示： 可以在NUS Data Commons用NUS ID登录后在Cisco MSE下载。 经过分析处理，得到的结果图如下所示： 蓝色线条 代表总人数 红色线条 代表平均停留时间 绿色线条 代表流入率 黑色线条 代表流出率 上图是周一E1 6楼3月19号周一的情况。首先蓝色线条有5个峰值，而红色线条有5段逐渐增加的区间。两者结合，我们可知E1该天有5个上课时间段：9AM-11AM, 12PM-2PM, 2PM-4PM, 4PM-6PM, 6PM-9PM。因为在上课时间，总人数肯定比较多，随着课堂的进行，dwell time停留时间也在逐渐增加。在课堂的开始和下课阶段，流入和流出率较大。晚上的课大多数都是master课程，老师一般会在7:30左右课间休息，8:30左右下课。图中的结果和作者亲身经历也完全吻合，侧面说明我们处理分析数据的方法是正确的。 那如何分析食堂的数据呢？大家肯定想知道，什么时间去吃饭，不算太早但排队的人也不多呢？本文分析了2018年春季第10周（3.19-3.23）的数据，采用的分析方法是: 一般在总人数陡增前到达食堂是比较稳的，迟了队伍前面就是千军万马。 平均停留时间开始急速下降的时候，因为如果没有顾客，食堂的device平均停留时间会由于食堂员工的存在随时间不断增加。当有大量学生来时，平均停留时间会因为基数的增大而开始下降。 流入流出率这里不采用，是因为根据作者的亲身经历来看，每分钟的流入流出率因为不可能那么大。误差估计是WiFi系统对于每分钟probing（探测）设备的统计误差，时有时无造成的。 工学院食堂Engineer师生常去的食堂，价格也超级便宜。队伍比较长的一般是西餐，日本料理等。感觉这学期在E1的课比较少，每周只有周一晚上才去吃饭。下图是周一工学院食堂的情况，时间为10AM–7:30PM 从图中我们可以看出，在11:31时，蓝色线条总人数开始迅速增加，红色线条平均停留时间也开始下降，这不正是暴风雨前的预兆吗？说明这个时间是用餐高峰期的开始。同样的，晚餐的用餐高峰期是从5:20开始的。 文学院食堂文学院食堂作者最爱的是海南鸡饭，三楼凉拌功夫的麻辣香锅也很不错。作者曾经有一次亲身经历，11:40到文学院食堂，人多到我想放弃。。。下图是周一文学院食堂的情况，时间为10AM–7:30PM 文学院食堂从11:20，平均停留时间就开始下滑，11:30后总人数也是急剧攀升。说明这个11:20-11:30时间是用餐高峰期的开始。 晚餐虽然呈现出变化趋势，但真的一点都不拥挤。。。 YIH食堂YIH的mixed food每次人都超级多，排队时还经常可以吃狗粮，美滋滋。但YIH相比于前面两个食堂，人数明显是少很多，因为食堂本来就不是很大。下图是周一YIH食堂的情况，时间为10AM–7:30PM 从上图可以看出，午餐高峰时间从11:20开始，总人数开始增加，平均停留时间迅速减小，这不正是千军万马来临前的预兆吗？ 同样的，晚餐高峰是从5:29开始的。 表格总结 划重点每个食堂都分析了一周5天的数据，结果汇总在下表： 敲黑板:一般来说中午下课时间大概是在11:30，所以赶在这之前去食堂，人都会比较少。晚上除了YIH，其余两个食堂也不怎么拥挤。 剩下的图：周二到周五 最后的吐槽最后的一个月，马上就要毕业了，最近忙的没有时间写博客。课程，项目，论文，期末考试，找工作都是一座座艰难的大山。狗住Uo･ｪ･oU加油٩(●˙▿˙●)۶…⋆ฺ PS: 如果对这个分析有更好的建议，或者发现了错误之处。欢迎交流，联系方式: QQ: 601300870 Email: fainyang@foxmail.com]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>NUS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小白也会用的微信机器人]]></title>
    <url>%2Fpost%2FRobot%2F</url>
    <content type="text"><![CDATA[天下武功，唯快不破这一篇文章是讲解如何安装微信自动回复机器人，独乐乐不如众乐乐。画风突转，先来一段鸡汤：并不是每个人都值得你腾出手中的事情秒回，如果有那么一个人，让你情不自禁地秒回了，说明那个人何其重要。或者说，你被别人秒回，又是多么温暖的存在啊。他秒回的瞬间，仿佛在说：你在我心中，很重要。 只可惜我只是一个机器人，惊不惊喜，意不意外？ 废话不多说，先来看一看效果图： 看完是不是有点小激动呢？ 老司机通道：会python的直接往下拉--看运行机器人程序 第一步安装python环境俗话说，人生苦短，我用python。安装python就像安装游戏、QQ一样，去官网下载安装包，只是安装后桌面没有运行图标，而是在我们的计算机上安装了一个运行环境。 看Windows-python安装教程如果不明白的话，再看看视频教程。 用苹果电脑的点击观看苹果电脑python安装教程。如果看不懂，可以去视频网站搜python安装教学视频，一边看视频一边依葫芦画瓢，我在这里就不详细说明了。万事开头难，搞不懂的话你可以微信问我呀，哈哈。 安装好以后，在Windows命令行 or Mac的终端检查一下python的version版本 安装python包当你把python环境安装好了以后，接下来你需要安装python包（python包是武林高手们打造的神兵利器，从新手村刚刚出来的你再也不用苦苦磨炼，自己去做武器啦） 那么问题来了，你怎么样从大侠手中借到神兵利器？？？这个时候就需要我们常说的py交易（开玩笑的啦），肯定是用pip。此外，这个机器人自动回复，需要两个包：一个是requests，另一个是itchat。 在Windows命令行 or Mac的终端 输入以下命令123pip install requestspip install itchat 当用pip借到大佬们的神兵利器后，终于可以开始打怪升级了，美滋滋。 运行机器人程序第一步需要点击下载源代码 下载时存放的地点要记住。下载之后解压文件Test-master.zip，其中的tuling.py就是我们的微信自动回复机器人小程序 。在文件夹中找到tuling.py,右键=&gt;打开方式用记事本打开，其中有两个地方需要修改。 第一个是图灵机器人的apikey，首先点击打开图灵机器人网站注册一个账号，免费创建一个机器人，得到机器人的apikey 第二个地方就是： 1itchat.auto_login(enableCmdQR=2) 修改为如下形式：这样是为了弹窗形式二维码比命令行形式的二维码清晰1itchat.auto_login() 至此，我们得到了机器人apikey，修改了二维码形式，就可以运行tuling.py了。 （最简单的小白法） Mac的终端 输入以下命令：12cd xxxx/Test-master #注释：先移动到tuling.py 所在文件python tuling.py #释：运行tuling.py Windows用户在Test-master文件夹打开命令行，方法为：在此文件夹窗口内空白区域右键单击（需要同时按住Shift），从菜单中选择＂在此处打开命令行窗口＂的项。 然后在命令窗口输入1python tuling.py 如果前面python包成功安装，运行将会弹出来一个网页登录的二维码。微信扫码登录后，看到命令窗口的个人信息就意味着大功告成了。12345678Getting uuid of QR code.Downloading QR code.Please scan the QR code to log in.Please press confirm on your phone.Loading the contact, this may take a little while.TERM environment variable not set.Login successfully as Fain 费洋Start auto replying. 但是这个机器人有一个缺陷：一旦运行python的电脑断网、休眠、关机。那么自动回复将会失效，因为自动回复的核心是电脑运行python调用图灵机器人来进行回复。但是对于小白来讲，这就已经足够~(≧▽≦)~啦啦啦。 兽（瘦）人永不为奴，云服务器永不关机我这周刚买的腾讯云服务器，学生优惠下来3年360，超级划算的。 我选择的系统是CentOS7.4（自带python2.7），需要安装python3.6–请参考教程1 和教程2 安装好python环境以后，也需要安装两个包，一个是requests，另一个是itchat。然后是在本地用scp把tuling.py 上传到云服务器，方法请参考这里。1scp 本地文件地址 云服务器登录名@云服务器公网IP/域名:云服务器文件地址 上传完成以后，运行试一试？结果你会发现当我们远程ssh关闭的时候，云服务器中的python程序也关闭了。为了能长时间运行，你需要使用Linux 技巧来续几年。 1setsid python tuling.py 这样我们的机器人就能在云服务器一直运行啦，直到天荒地老，海枯石烂？ 错！是服务器到期欠费。]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排列组合了解一下(阿里笔试题改编)]]></title>
    <url>%2Fpost%2FCombination%2F</url>
    <content type="text"><![CDATA[问题介绍假设有小费和小王俩好基友，天天形影不离，二人分在一个组。为了减少迟到的现象，班主任规定如下： 迟到一次，则当事人记一分。（迟到） 小组两人在某一天同时迟到，则小组总分再记一分。（连坐） 一周内如果每天都迟到，则当事人再扣一分。（太皮了） 三种情况可累加记分，一周结算一次小组总分。 肯定有人想说 举个例子好了下图为某一周的出勤情况：从图中看出小费同学比较皮，天天迟到！小王同学有两天和小费同学一起开黑，导致了迟到。所以总的小组计分为10分！ 那么问题来了：如果已知某一周小组的总分情况，列出可能的出勤表 咸鱼采用的暴力破解法有两个对象，每个对象有5个记录。每次记录的值有两种情况，我们可以暴力枚举出所有的情况。一共也才2的10次方，1024种情况。对于计算机来说，当然是小菜一碟咯。 所有上面的出勤图就可以简化为0-1数值图： 接下来问题就变成，如何枚举出这1024种情况？ 2行5列一共10个值，循环列出0-1111111111二进制数的情况，高位补0。 如上图，2列是独立的，我们只需求出5位的情况，两列互相遍历即可。 用python自带的 itertools库，分分钟枚举完成。 12345678910111213import itertoolsdef main(start_day,faith_score): Calendar=[[6,6,6,6,6],[6,6,6,6,6]] #模拟日历2行5列 L=list(itertools.product([0,1],repeat=5)) #枚举产生 leng=len(L) for i in range(leng):#两次遍历 for j in range(leng): Calendar[0]=L[i] Calendar[1]=L[j] if sumcredit(Calendar)==faith_score:#判断情况 gg=todate(Calendar,start_day) print(gg) #输出情况 只要有了枚举的所有情况，判断计分则是很容易的事情。 123456789101112131415161718192021222324252627282930def credit1(L): #迟到一次扣一分 credit=0 for i in L[0]: if i==1: credit+=1 for j in L[1]: if j==1: credit+=1 return creditdef credit2 (L): #一起迟到，多扣一分 credit=0 for i in range(5): if L[0][i]==1 and L[1][i]==1: credit+=1 return creditdef credit3 (L): #连续迟到，罪加一等 credit=0 if 0 not in L[0]: credit+=1 if 0 not in L[1]: credit+=1 return creditdef sumcredit(L): #累加总分 c1=credit1(L) c2=credit2(L) c3=credit3(L) return c1+c2+c3 时间问题，不容小觑因为时间在跨月份是时候有点麻烦，不能用普通的++，但我们可以用datetime库呀。输入一个起始时间，我们要得到那一周的5天。timedelta()函数你值得拥有。 12345678910111213141516171819from datetime import datetime,timedeltadef get_date(date): #Y表示四位数的年份(0-9999) date_begin=datetime.strptime(date,'%Y%m%d') time=str(datetime.date(date_begin)) date1=date_begin+timedelta(days=1) #加1s，哈哈 time1=str(datetime.date(date1)) date2=date_begin+timedelta(days=2) time2=str(datetime.date(date2)) date3=date_begin+timedelta(days=2) time3=str(datetime.date(date3)) date4=date_begin+timedelta(days=2) time4=str(datetime.date(date4)) return time,time1,time2,time3,time4 最后我们在输出 出勤情况的时候，将那个简化后的二维数组List=&gt;日历对应起来。 1234567891011def todate(L,date): time,time1,time2,time3,time4=get_date(date) record=[time+'-小费',time+'-小王',time1+'-小费',time1+'-小王',time2+'-小费',\ time2+'-小王',time3+'-小费',time3+'-小王',time4+'-小费',time4+'-小王'] L1=L[0]+L[1] for i in range(len(L1)): if L1[i]==1: #1 代表迟到 record[i]+='(迟到)' else: #0代表没迟到 record[i]+='(正常)' return record 假设我们输入date=20180305,score=0输出如下结果：123456['2018-03-04-小费(正常)', '2018-03-04-小王(正常)', '2018-03-05-小费(正常)', '2018-03-05-小王(正常)', '2018-03-06-小费(正常)', '2018-03-06-小王(正常)', '2018-03-06-小费(正常)', '2018-03-06-小王(正常)', '2018-03-06-小费(正常)', '2018-03-06-小王(正常)'][Finished in 0.2s] 假设我们输入date=20180305,score=1输出如下结果： 最后一点废话有一篇关于itertools的文章这段代码很Pythonic | 相见恨晚的 itertools 库 安利一下。此文章的python源代码 马上就要毕业了，再也没有当学生那种无忧无虑的感觉了。以前贪玩欠的债，找工作的时候哭出来。去面试才知道自己有多菜，所幸我还比较naive，未来珍惜时间，好好学习。狗住，加油！]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时间求差值timestampdiff]]></title>
    <url>%2Fpost%2Ftimestampdiff%2F</url>
    <content type="text"><![CDATA[问题背景介绍因为Prof想知道每个building里的average-dwell时间，NUS-WiFi数据库提供了current-time，first-time。思路就是根据两者时间的差值来估计stay in building的时间。 人生苦短，首选python第一想法当然是用python，用python包：time, datetime.代码如下： 123456789101112131415import timeimport datetimedef difftime(begintime,endtime): date1=time.strptime(begintime,'%Y-%m-%d %H:%M:%S') date2=time.strptime(endtime,'%Y-%m-%d %H:%M:%S') #y两位数的年份表示（00-99） #Y四位数的年份表示（000-9999） date3=datetime.datetime( date1[0],date1[1],date1[2],date1[3],date1[4],date1[5]) date4=datetime.datetime( date2[0],date2[1],date2[2],date2[3],date2[4],date2[5]) minutes=(date4-date3).seconds/60 return minutes 结果如下图： MySQL 表示不服上学期我用python做的统计工作，例如每分钟有多少device，或者每个device在building里停留了多少分钟.用python至少得写30+行代码去读写csv文件，在MySQL就是一行代码的事情，相见恨晚。无知限制了我的生产力！MySQL的数据类型里有时间戳格式timestamp。也有专门计算时间差值的timestampdiff函数。TIMESTAMPDIFF(unit,begin,end);返回end-begin的时间差值。 1select timestampdiff(minute,firstime,curtime) 结果如下图： INSERT遇到问题了我想把timestampdiff返回的值插入在表的最后，先创建一个字段（列），再用insert插入，结果遇到了问题。 1insert into test (diff) select timestampdiff(minute,firstime,curtime) from test; 如图所示，结果是插在了diff列，但直接插在表的后面，没有覆盖原有的值。经过思考后，我尝试了 update的方法。 1update test set diff=timestampdiff(minute,firstime,curtime); 终于成功了！ 咸鱼的叹息python定义了一个函数来计算，用MySQL就是一句话的事情。光找这句话我就花了好久，还得好好学习。还是在项目中体会得多，光看书是不行的，纸上得来终觉浅。 很惭愧，连一点微小的工作都没有做，打扰了。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开始blog啦]]></title>
    <url>%2Fpost%2Fblog%2F</url>
    <content type="text"><![CDATA[第一篇post虽然还不知道怎么用，先把这个网站搭起再说。生活需要多点乐趣，人生苦短，需要一点甜甜的爱。最幸福的事情莫过于找到所爱，所爱的事业，所爱的人。除了美食，最近我也慢慢开始发现编程的乐趣。今年的愿望是：每晚早点休息，年轻人不要熬夜。晚安]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
</search>
